{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d784b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import time\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5aaf267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7f935bb96c10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configura√ß√£o do backend do matplotlib para notebooks\n",
    "import os\n",
    "# Remove a vari√°vel de ambiente que causa conflito\n",
    "if 'MPLBACKEND' in os.environ:\n",
    "    del os.environ['MPLBACKEND']\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Backend n√£o-interativo que funciona em qualquer ambiente\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Para garantir que os gr√°ficos sejam exibidos no notebook\n",
    "plt.ion()  # Ativa modo interativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67a834",
   "metadata": {},
   "source": [
    "# Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61bc40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/datasets/netflix_titles.csv\n"
     ]
    }
   ],
   "source": [
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "# garante que encontramos o dataset independentemente do cwd do notebook\n",
    "input_file = root / 'datasets' / 'netflix_titles.csv'\n",
    "\n",
    "print(f\"Lendo: {input_file}\")\n",
    "\n",
    "df = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab55fb",
   "metadata": {},
   "source": [
    "## An√°lise geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306758f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas no CSV: 8807\n",
      "Atores com pelo menos 1 co-ator: 36039\n",
      "Atores com apari√ß√µes registradas: 36439\n",
      "Pares √∫nicos de atores (potenciais arestas): 289207\n",
      "\n",
      "Top 20 por grau (n√∫mero de coatores):\n",
      "Anupam Kher: 273\n",
      "Samuel L. Jackson: 239\n",
      "Takahiro Sakurai: 228\n",
      "Fred Tatasciore: 226\n",
      "Yuichi Nakamura: 223\n",
      "Yuki Kaji: 220\n",
      "Shah Rukh Khan: 210\n",
      "Fred Armisen: 209\n",
      "Akshay Kumar: 193\n",
      "Katsuyuki Konishi: 191\n",
      "Jun Fukuyama: 188\n",
      "Om Puri: 187\n",
      "Junichi Suwabe: 185\n",
      "Naseeruddin Shah: 183\n",
      "Boman Irani: 183\n",
      "Hiroshi Kamiya: 182\n",
      "James Franco: 182\n",
      "Maya Rudolph: 181\n",
      "Paresh Rawal: 179\n",
      "Amitabh Bachchan: 178\n",
      "\n",
      "Top 20 por apari√ß√µes:\n",
      "Anupam Kher: 43\n",
      "Shah Rukh Khan: 35\n",
      "Julie Tejwani: 33\n",
      "Naseeruddin Shah: 32\n",
      "Takahiro Sakurai: 32\n",
      "Rupa Bhimani: 31\n",
      "Akshay Kumar: 30\n",
      "Om Puri: 30\n",
      "Yuki Kaji: 29\n",
      "Amitabh Bachchan: 28\n",
      "Paresh Rawal: 28\n",
      "Boman Irani: 27\n",
      "Rajesh Kava: 26\n",
      "Vincent Tong: 26\n",
      "Andrea Libman: 25\n",
      "Kareena Kapoor: 25\n",
      "Samuel L. Jackson: 24\n",
      "John Cleese: 24\n",
      "Jigna Bhardwaj: 23\n",
      "Fred Tatasciore: 23\n",
      "\n",
      "Arquivos intermedi√°rios salvos em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2: Parse do CSV e constru√ß√£o das estruturas de co-atores\n",
    "\n",
    "actor_coactors = defaultdict(set)\n",
    "pair_counts = defaultdict(int)\n",
    "actor_appearances = defaultdict(int)\n",
    "\n",
    "for idx, cast in enumerate(df['cast'].fillna('')):\n",
    "    if not cast:\n",
    "        continue\n",
    "    actors = [a.strip() for a in cast.split(',') if a.strip()]\n",
    "    for a in actors:\n",
    "        actor_appearances[a] += 1\n",
    "    for a, b in combinations(actors, 2):\n",
    "        key = tuple(sorted((a, b)))\n",
    "        pair_counts[key] += 1\n",
    "        actor_coactors[a].add(b)\n",
    "        actor_coactors[b].add(a)\n",
    "\n",
    "num_actors_with_coactors = len(actor_coactors)\n",
    "num_actors_with_appearances = len(actor_appearances)\n",
    "num_pairs = len(pair_counts)\n",
    "\n",
    "print(f\"Total de linhas no CSV: {df.shape[0]}\")\n",
    "print(f\"Atores com pelo menos 1 co-ator: {num_actors_with_coactors}\")\n",
    "print(f\"Atores com apari√ß√µes registradas: {num_actors_with_appearances}\")\n",
    "print(f\"Pares √∫nicos de atores (potenciais arestas): {num_pairs}\")\n",
    "\n",
    "# Tops para inspe√ß√£o\n",
    "top_by_degree = sorted(((actor, len(neigh)) for actor, neigh in actor_coactors.items()), key=lambda x: x[1], reverse=True)[:20]\n",
    "print('\\nTop 20 por grau (n√∫mero de coatores):')\n",
    "for actor, deg in top_by_degree:\n",
    "    print(f\"{actor}: {deg}\")\n",
    "\n",
    "top_by_appearances = sorted(actor_appearances.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "print('\\nTop 20 por apari√ß√µes:')\n",
    "for actor, cnt in top_by_appearances:\n",
    "    print(f\"{actor}: {cnt}\")\n",
    "\n",
    "# Salvando intermedi√°rios em results/q1\n",
    "out_dir = root / 'results'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Salvar tops em CSVs para inspe√ß√£o\n",
    "pd.DataFrame(top_by_appearances, columns=['Actor', 'Appearances']).to_csv(out_dir / 'top_by_appearances.csv', index=False)\n",
    "pd.DataFrame(top_by_degree, columns=['Actor', 'Degree']).to_csv(out_dir / 'top_by_degree.csv', index=False)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nArquivos intermedi√°rios salvos em: {out_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2971104",
   "metadata": {},
   "source": [
    "## Grafo geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f489ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de atores √∫nicos: 36439\n",
      "Total de pares de coatores: 289207\n",
      "\n",
      "Grafo de coautoria: n√≥s=36439, arestas=289207\n",
      "Grafo salvo em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/geral/grafo_coautoria.graphml\n"
     ]
    }
   ],
   "source": [
    "# Montagem do grafo de coautoria geral usando networkx\n",
    "\n",
    "# Obter todos os atores √∫nicos\n",
    "all_actors = set(actor_appearances.keys())\n",
    "\n",
    "print(f\"Total de atores √∫nicos: {len(all_actors)}\")\n",
    "print(f\"Total de pares de coatores: {len(pair_counts)}\")\n",
    "\n",
    "# Construir grafo ponderado (undirected)\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(all_actors)\n",
    "\n",
    "for (a, b), w in pair_counts.items():\n",
    "    # adicionar aresta com atributo weight (n√∫mero de vezes que atuaram juntos)\n",
    "    G.add_edge(a, b, weight=w)\n",
    "\n",
    "n_nodes = G.number_of_nodes()\n",
    "n_edges = G.number_of_edges()\n",
    "print(f\"\\nGrafo de coautoria: n√≥s={n_nodes}, arestas={n_edges}\")\n",
    "\n",
    "# Salvando o grafo em formato GraphML para an√°lise posterior\n",
    "geral_dir = out_dir / 'geral'\n",
    "geral_dir.mkdir(parents=True, exist_ok=True)\n",
    "graphml_path = geral_dir / 'grafo_coautoria.graphml'\n",
    "nx.write_graphml(G, graphml_path)\n",
    "print(f\"Grafo salvo em: {graphml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b09076",
   "metadata": {},
   "source": [
    "## Medidas de centralidade geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e3731e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando m√©tricas globais...\n",
      "Densidade: 0.00043563\n",
      "N√∫mero de n√≥s: 36439\n",
      "N√∫mero de arestas: 289207\n",
      "Componentes: 874; maior componente: 32935 n√≥s\n",
      "‚úì M√©tricas globais salvas em: global_metrics.csv\n",
      "\n",
      "[1/5] Calculando Degree...\n",
      "‚úì Degree calculado e normalizado para 36439 atores\n",
      "\n",
      "[2/5] Carregando Degree Centrality do cache...\n",
      "‚úì Degree Centrality carregado do cache (j√° normalizado)\n",
      "\n",
      "[3/5] Calculando Closeness Centrality...\n",
      "‚úì Closeness Centrality calculado, normalizado e salvo em cache\n",
      "\n",
      "[4/5] Calculando PageRank...\n",
      "‚úì PageRank calculado, normalizado e salvo em cache\n",
      "\n",
      "[5/5] Calculando Betweenness Centrality... (pode demorar)\n",
      "‚úì Betweenness Centrality calculado, normalizado e salvo em cache\n",
      "\n",
      "Salvando resultados finais...\n",
      "‚úì Todas as centralidades (normalizadas): graph_metrics.csv\n",
      "‚úì Top 10 por Degree (normalizado): top10_degree.csv\n",
      "‚úì Top 10 por Betweenness (normalizado): top10_betweenness.csv\n",
      "‚úì Top 10 por Closeness (normalizado): top10_closeness.csv\n",
      "‚úì Top 10 por PageRank (normalizado): top10_pagerank.csv\n",
      "\n",
      "============================================================\n",
      "Todos os arquivos salvos em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/geral\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Top 10 por Degree (normalizado):\n",
      "============================================================\n",
      "                   Actor    Degree\n",
      "26336        Anupam Kher  1.000000\n",
      "24280  Samuel L. Jackson  0.875458\n",
      "4293    Takahiro Sakurai  0.835165\n",
      "14369    Fred Tatasciore  0.827839\n",
      "24310    Yuichi Nakamura  0.816850\n",
      "15482          Yuki Kaji  0.805861\n",
      "4874      Shah Rukh Khan  0.769231\n",
      "24257       Fred Armisen  0.765568\n",
      "17125       Akshay Kumar  0.706960\n",
      "30580  Katsuyuki Konishi  0.699634\n",
      "\n",
      "============================================================\n",
      "Top 10 por Betweenness (normalizado):\n",
      "============================================================\n",
      "                      Actor  Betweenness\n",
      "26336           Anupam Kher     1.000000\n",
      "16362  Sahajak Boonthanakit     0.596754\n",
      "35406               Om Puri     0.526919\n",
      "15650             Iko Uwais     0.500941\n",
      "32900          Ben Kingsley     0.449836\n",
      "30277       Christopher Lee     0.441398\n",
      "27287           Steven Yeun     0.423129\n",
      "20247          Danny Glover     0.399337\n",
      "20330        Haluk Bilginer     0.359689\n",
      "17441       Priyanka Chopra     0.335706\n",
      "\n",
      "============================================================\n",
      "Top 10 por Closeness (normalizado):\n",
      "============================================================\n",
      "                    Actor  Closeness\n",
      "10981       Alfred Molina   1.000000\n",
      "24280   Samuel L. Jackson   0.999819\n",
      "13231         Lena Headey   0.997466\n",
      "8328        Gerard Butler   0.989915\n",
      "32900        Ben Kingsley   0.988011\n",
      "6155   Chlo√´ Grace Moretz   0.987351\n",
      "35273        James Franco   0.987311\n",
      "35503        Willem Dafoe   0.985393\n",
      "5609         Nicolas Cage   0.982399\n",
      "25794        Helen Mirren   0.982184\n",
      "\n",
      "============================================================\n",
      "Top 10 por PageRank (normalizado):\n",
      "============================================================\n",
      "                   Actor  PageRank\n",
      "26336        Anupam Kher  1.000000\n",
      "4874      Shah Rukh Khan  0.790993\n",
      "13088   Naseeruddin Shah  0.709278\n",
      "24280  Samuel L. Jackson  0.704034\n",
      "17125       Akshay Kumar  0.695227\n",
      "35406            Om Puri  0.674130\n",
      "8131        Paresh Rawal  0.651386\n",
      "14369    Fred Tatasciore  0.651216\n",
      "4869         Boman Irani  0.634042\n",
      "32909   Amitabh Bachchan  0.628947\n",
      "\n",
      "============================================================\n",
      "M√©tricas Globais:\n",
      "============================================================\n",
      "                   Metric          Value\n",
      "0                   Nodes   36439.000000\n",
      "1                   Edges  289207.000000\n",
      "2                 Density       0.000436\n",
      "3              Components     874.000000\n",
      "4  Largest_Component_Size   32935.000000\n"
     ]
    }
   ],
   "source": [
    "# C√°lculo das centralidades e m√©tricas globais do grafo de coautoria\n",
    "# Com sistema de cache - calcula, normaliza e salva incrementalmente\n",
    "\n",
    "print(\"Calculando m√©tricas globais...\")\n",
    "\n",
    "# M√©tricas globais\n",
    "density = nx.density(G)\n",
    "components = list(nx.connected_components(G))\n",
    "num_components = len(components)\n",
    "largest_cc = max(components, key=len) if components else set()\n",
    "largest_cc_size = len(largest_cc)\n",
    "\n",
    "print(f\"Densidade: {density:.6g}\")\n",
    "print(f\"N√∫mero de n√≥s: {n_nodes}\")\n",
    "print(f\"N√∫mero de arestas: {n_edges}\")\n",
    "print(f\"Componentes: {num_components}; maior componente: {largest_cc_size} n√≥s\")\n",
    "\n",
    "# Salvar m√©tricas globais\n",
    "global_metrics = pd.DataFrame({\n",
    "    'Metric': ['Nodes', 'Edges', 'Density', 'Components', 'Largest_Component_Size'],\n",
    "    'Value': [n_nodes, n_edges, density, num_components, largest_cc_size]\n",
    "})\n",
    "global_metrics.to_csv(geral_dir / 'global_metrics.csv', index=False)\n",
    "print(f\"‚úì M√©tricas globais salvas em: global_metrics.csv\")\n",
    "\n",
    "# ========================================================================\n",
    "# Fun√ß√£o auxiliar para normalizar valores\n",
    "# ========================================================================\n",
    "def normalize_dict(values_dict):\n",
    "    \"\"\"Normaliza valores de um dicion√°rio para o intervalo [0, 1]\"\"\"\n",
    "    values = list(values_dict.values())\n",
    "    min_val = min(values)\n",
    "    max_val = max(values)\n",
    "    if max_val == min_val:\n",
    "        return {k: 0.0 for k in values_dict.keys()}\n",
    "    return {k: (v - min_val) / (max_val - min_val) for k, v in values_dict.items()}\n",
    "\n",
    "# ========================================================================\n",
    "# C√°lculo incremental de centralidades com cache (valores normalizados)\n",
    "# ========================================================================\n",
    "\n",
    "# Inicializar DataFrame base com os atores\n",
    "actors_list = list(G.nodes())\n",
    "metrics_df = pd.DataFrame({'Actor': actors_list})\n",
    "\n",
    "# Degree raw (sempre calcula, √© r√°pido)\n",
    "print('\\n[1/5] Calculando Degree...')\n",
    "degree_raw = dict(G.degree())\n",
    "degree_normalized = normalize_dict(degree_raw)\n",
    "metrics_df['Degree'] = [degree_normalized.get(n, 0) for n in actors_list]\n",
    "print(f\"‚úì Degree calculado e normalizado para {len(actors_list)} atores\")\n",
    "\n",
    "# ========================================================================\n",
    "# 2. Degree Centrality (j√° vem normalizado do NetworkX)\n",
    "# ========================================================================\n",
    "degree_cache_file = geral_dir / 'cache_degree_centrality.pkl'\n",
    "if degree_cache_file.exists():\n",
    "    print('\\n[2/5] Carregando Degree Centrality do cache...')\n",
    "    with open(degree_cache_file, 'rb') as f:\n",
    "        degree_c = pickle.load(f)\n",
    "    print(f\"‚úì Degree Centrality carregado do cache (j√° normalizado)\")\n",
    "else:\n",
    "    print('\\n[2/5] Calculando Degree Centrality...')\n",
    "    degree_c = nx.degree_centrality(G)\n",
    "    # Degree centrality j√° vem normalizado do NetworkX\n",
    "    # Salvar cache\n",
    "    with open(degree_cache_file, 'wb') as f:\n",
    "        pickle.dump(degree_c, f)\n",
    "    print(f\"‚úì Degree Centrality calculado e salvo em cache (j√° normalizado)\")\n",
    "\n",
    "metrics_df['DegreeCentrality'] = [degree_c.get(n, 0) for n in actors_list]\n",
    "\n",
    "# ========================================================================\n",
    "# 3. Closeness Centrality\n",
    "# ========================================================================\n",
    "closeness_cache_file = geral_dir / 'cache_closeness_centrality.pkl'\n",
    "if closeness_cache_file.exists():\n",
    "    print('\\n[3/5] Carregando Closeness Centrality do cache...')\n",
    "    with open(closeness_cache_file, 'rb') as f:\n",
    "        closeness_c = pickle.load(f)\n",
    "    print(f\"‚úì Closeness Centrality carregado do cache (j√° normalizado)\")\n",
    "else:\n",
    "    print('\\n[3/5] Calculando Closeness Centrality...')\n",
    "    closeness_c_raw = nx.closeness_centrality(G)\n",
    "    # Normalizar antes de salvar\n",
    "    closeness_c = normalize_dict(closeness_c_raw)\n",
    "    # Salvar cache normalizado\n",
    "    with open(closeness_cache_file, 'wb') as f:\n",
    "        pickle.dump(closeness_c, f)\n",
    "    print(f\"‚úì Closeness Centrality calculado, normalizado e salvo em cache\")\n",
    "\n",
    "metrics_df['Closeness'] = [closeness_c.get(n, 0) for n in actors_list]\n",
    "\n",
    "# ========================================================================\n",
    "# 5. PageRank\n",
    "# ========================================================================\n",
    "pagerank_cache_file = geral_dir / 'cache_pagerank.pkl'\n",
    "if pagerank_cache_file.exists():\n",
    "    print('\\n[4/5] Carregando PageRank do cache...')\n",
    "    with open(pagerank_cache_file, 'rb') as f:\n",
    "        pagerank = pickle.load(f)\n",
    "    print(f\"‚úì PageRank carregado do cache (j√° normalizado)\")\n",
    "else:\n",
    "    print('\\n[4/5] Calculando PageRank...')\n",
    "    pagerank_raw = nx.pagerank(G, alpha=0.85, max_iter=100)\n",
    "    # Normalizar antes de salvar\n",
    "    pagerank = normalize_dict(pagerank_raw)\n",
    "    # Salvar cache normalizado\n",
    "    with open(pagerank_cache_file, 'wb') as f:\n",
    "        pickle.dump(pagerank, f)\n",
    "    print(f\"‚úì PageRank calculado, normalizado e salvo em cache\")\n",
    "\n",
    "metrics_df['PageRank'] = [pagerank.get(n, 0) for n in actors_list]\n",
    "\n",
    "# ========================================================================\n",
    "# 3. Betweenness Centrality\n",
    "# ========================================================================\n",
    "betweenness_cache_file = geral_dir / 'cache_betweenness_centrality.pkl'\n",
    "if betweenness_cache_file.exists():\n",
    "    print('\\n[5/5] Carregando Betweenness Centrality do cache...')\n",
    "    with open(betweenness_cache_file, 'rb') as f:\n",
    "        betweenness_c = pickle.load(f)\n",
    "    print(f\"‚úì Betweenness Centrality carregado do cache (j√° normalizado)\")\n",
    "else:\n",
    "    print('\\n[5/5] Calculando Betweenness Centrality... (pode demorar)')\n",
    "    betweenness_c_raw = nx.betweenness_centrality(G)\n",
    "    # Normalizar antes de salvar\n",
    "    betweenness_c = normalize_dict(betweenness_c_raw)\n",
    "    # Salvar cache normalizado\n",
    "    with open(betweenness_cache_file, 'wb') as f:\n",
    "        pickle.dump(betweenness_c, f)\n",
    "    print(f\"‚úì Betweenness Centrality calculado, normalizado e salvo em cache\")\n",
    "\n",
    "metrics_df['Betweenness'] = [betweenness_c.get(n, 0) for n in actors_list]\n",
    "\n",
    "\n",
    "# ========================================================================\n",
    "# Salvar resultados finais (j√° normalizados)\n",
    "# ========================================================================\n",
    "print('\\nSalvando resultados finais...')\n",
    "\n",
    "# CSV com todas as m√©tricas de centralidade (j√° normalizadas)\n",
    "metrics_csv = geral_dir / 'graph_metrics.csv'\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "print(f\"‚úì Todas as centralidades (normalizadas): {metrics_csv.name}\")\n",
    "\n",
    "# CSV com top 10 de cada medida (valores j√° normalizados)\n",
    "top10_degree = metrics_df.sort_values('Degree', ascending=False).head(10)[['Actor', 'Degree']]\n",
    "top10_betweenness = metrics_df.sort_values('Betweenness', ascending=False).head(10)[['Actor', 'Betweenness']]\n",
    "top10_closeness = metrics_df.sort_values('Closeness', ascending=False).head(10)[['Actor', 'Closeness']]\n",
    "top10_pagerank = metrics_df.sort_values('PageRank', ascending=False).head(10)[['Actor', 'PageRank']]\n",
    "\n",
    "top10_degree.to_csv(geral_dir / 'top10_degree.csv', index=False)\n",
    "top10_betweenness.to_csv(geral_dir / 'top10_betweenness.csv', index=False)\n",
    "top10_closeness.to_csv(geral_dir / 'top10_closeness.csv', index=False)\n",
    "top10_pagerank.to_csv(geral_dir / 'top10_pagerank.csv', index=False)\n",
    "\n",
    "print(f\"‚úì Top 10 por Degree (normalizado): top10_degree.csv\")\n",
    "print(f\"‚úì Top 10 por Betweenness (normalizado): top10_betweenness.csv\")\n",
    "print(f\"‚úì Top 10 por Closeness (normalizado): top10_closeness.csv\")\n",
    "print(f\"‚úì Top 10 por PageRank (normalizado): top10_pagerank.csv\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Todos os arquivos salvos em: {geral_dir}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Mostrar top 10 por cada medida\n",
    "print('\\n' + '='*60)\n",
    "print('Top 10 por Degree (normalizado):')\n",
    "print('='*60)\n",
    "print(top10_degree)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Top 10 por Betweenness (normalizado):')\n",
    "print('='*60)\n",
    "print(top10_betweenness)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Top 10 por Closeness (normalizado):')\n",
    "print('='*60)\n",
    "print(top10_closeness)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Top 10 por PageRank (normalizado):')\n",
    "print('='*60)\n",
    "print(top10_pagerank)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('M√©tricas Globais:')\n",
    "print('='*60)\n",
    "print(global_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b716d4",
   "metadata": {},
   "source": [
    "## Detec√ß√£o de comunidades geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b623df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detec√ß√£o de comunidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e21fc8",
   "metadata": {},
   "source": [
    "# Grafo de 100 coautores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd31b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atores dispon√≠veis: 36039, selecionando TOP_N = 100 => selecionados: 100\n",
      "Pares no subgrafo dos TOP 100: 583\n",
      "Arquivos gerados (n√£o para Flourish ainda):\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/links_top.csv\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/top_actors.csv\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/filtered_pair_counts.pkl\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/top_actor_names.pkl\n",
      "\n",
      "Top 10 (dos selecionados) por grau:\n",
      "Anupam Kher: grau=273, apari√ß√µes=43\n",
      "Samuel L. Jackson: grau=239, apari√ß√µes=24\n",
      "Takahiro Sakurai: grau=228, apari√ß√µes=32\n",
      "Fred Tatasciore: grau=226, apari√ß√µes=23\n",
      "Yuichi Nakamura: grau=223, apari√ß√µes=19\n",
      "Yuki Kaji: grau=220, apari√ß√µes=29\n",
      "Shah Rukh Khan: grau=210, apari√ß√µes=35\n",
      "Fred Armisen: grau=209, apari√ß√µes=19\n",
      "Akshay Kumar: grau=193, apari√ß√µes=30\n",
      "Katsuyuki Konishi: grau=191, apari√ß√µes=12\n"
     ]
    }
   ],
   "source": [
    "# Etapa 3 (separada): Selecionar TOP_N atores por grau (conex√µes)\n",
    "# N√£o executo esta c√©lula automaticamente ‚Äî confirme quando quiser rodar.\n",
    "\n",
    "# Par√¢metro din√¢mico: altere antes de executar, se desejar\n",
    "TOP_N = 100\n",
    "\n",
    "# Determina paths conforme o notebook\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir = root / 'results' / 'q1'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Tenta usar vari√°veis em mem√≥ria (caso a c√©lula de parsing tenha sido executada);\n",
    "# caso contr√°rio, carrega os pickles gerados pela etapa de parsing.\n",
    "try:\n",
    "    actor_coactors\n",
    "    pair_counts\n",
    "    actor_appearances\n",
    "except NameError:\n",
    "    # tenta carregar arquivos em results/q1\n",
    "    try:\n",
    "        with open(out_dir / 'actor_coactors.pkl', 'rb') as f:\n",
    "            actor_coactors = pickle.load(f)\n",
    "        with open(out_dir / 'pair_counts.pkl', 'rb') as f:\n",
    "            pair_counts = pickle.load(f)\n",
    "        with open(out_dir / 'actor_appearances.pkl', 'rb') as f:\n",
    "            actor_appearances = pickle.load(f)\n",
    "        print('Carreguei pickles de', out_dir)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError('Estruturas de parsing n√£o encontradas em mem√≥ria nem em results/q1. Execute a c√©lula de parsing primeiro.')\n",
    "\n",
    "# Calcula grau (n√∫mero de coatores) e seleciona TOP_N\n",
    "degrees = {actor: len(neigh) for actor, neigh in actor_coactors.items()}\n",
    "all_actors_count = len(degrees)\n",
    "sorted_by_degree = sorted(degrees.items(), key=lambda x: x[1], reverse=True)\n",
    "top_actors = sorted_by_degree[:TOP_N]\n",
    "actual_top_n = len(top_actors)\n",
    "print(f\"Atores dispon√≠veis: {all_actors_count}, selecionando TOP_N = {TOP_N} => selecionados: {actual_top_n}\")\n",
    "\n",
    "top_names = [a for a, _ in top_actors]\n",
    "top_set = set(top_names)\n",
    "\n",
    "# Filtrar pares onde ambos est√£o no top\n",
    "filtered_pairs = {pair: cnt for pair, cnt in pair_counts.items() if pair[0] in top_set and pair[1] in top_set}\n",
    "num_filtered_pairs = len(filtered_pairs)\n",
    "print(f\"Pares no subgrafo dos TOP {actual_top_n}: {num_filtered_pairs}\")\n",
    "\n",
    "# --- Usando pandas para gerar os CSVs (mais simples e robusto) ---\n",
    "# links dataframe\n",
    "links_rows = [(a, b, cnt) for (a, b), cnt in filtered_pairs.items()]\n",
    "links_df = pd.DataFrame(links_rows, columns=['Source', 'Target', 'Movies_Count'])\n",
    "links_csv = out_dir / 'links_top.csv'\n",
    "links_df.to_csv(links_csv, index=False)\n",
    "\n",
    "# top actors dataframe\n",
    "top_rows = [(a, degrees.get(a, 0), actor_appearances.get(a, 0)) for a, _ in top_actors]\n",
    "top_df = pd.DataFrame(top_rows, columns=['Actor', 'Degree', 'Appearances'])\n",
    "top_csv = out_dir / 'top_actors.csv'\n",
    "top_df.to_csv(top_csv, index=False)\n",
    "\n",
    "# Salvar pickles √∫teis\n",
    "with open(out_dir / 'filtered_pair_counts.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_pairs, f)\n",
    "with open(out_dir / 'top_actor_names.pkl', 'wb') as f:\n",
    "    pickle.dump(top_names, f)\n",
    "\n",
    "print(f\"Arquivos gerados (n√£o para Flourish ainda):\\n- {links_csv}\\n- {top_csv}\\n- {out_dir / 'filtered_pair_counts.pkl'}\\n- {out_dir / 'top_actor_names.pkl'}\")\n",
    "\n",
    "# Resumo r√°pido dos 10 atores com maior grau selecionados\n",
    "print('\\nTop 10 (dos selecionados) por grau:')\n",
    "for actor, deg in top_actors[:10]:\n",
    "    print(f\"{actor}: grau={deg}, apari√ß√µes={actor_appearances.get(actor, 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca860426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomes no top: 100; pares filtrados: 583\n",
      "Grafo: n√≥s=100, arestas=583\n",
      "Densidade: 0.117778\n",
      "Componentes: 1; maior componente: 100 n√≥s\n",
      "\n",
      "Calculando centralidades... (isso pode levar algum tempo para betweenness se exato)\n",
      "\n",
      "M√©tricas salvas em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/graph_metrics.csv\n",
      "\n",
      "Top 10 por Degree:\n",
      "               Actor  Degree\n",
      "4    Yuichi Nakamura      27\n",
      "2   Takahiro Sakurai      26\n",
      "5          Yuki Kaji      25\n",
      "10      Jun Fukuyama      25\n",
      "25       Daisuke Ono      24\n",
      "75  Nobuhiko Okamoto      23\n",
      "43     Kana Hanazawa      23\n",
      "42         Ai Kayano      23\n",
      "50  Miyuki Sawashiro      22\n",
      "12    Junichi Suwabe      22\n",
      "\n",
      "Top 10 por Betweenness:\n",
      "                 Actor  Betweenness\n",
      "30       Kari Wahlgren     0.417440\n",
      "0          Anupam Kher     0.173614\n",
      "87  Chlo√´ Grace Moretz     0.126796\n",
      "83       Gerard Butler     0.096958\n",
      "89       Paul Giamatti     0.095672\n",
      "27     Elizabeth Banks     0.070178\n",
      "3      Fred Tatasciore     0.062150\n",
      "55       Alfred Molina     0.060203\n",
      "20       Nick Swardson     0.059847\n",
      "4      Yuichi Nakamura     0.051806\n",
      "\n",
      "Top 10 por Closeness:\n",
      "                 Actor  Closeness\n",
      "30       Kari Wahlgren   0.450000\n",
      "87  Chlo√´ Grace Moretz   0.445946\n",
      "89       Paul Giamatti   0.421277\n",
      "3      Fred Tatasciore   0.412500\n",
      "27     Elizabeth Banks   0.409091\n",
      "20       Nick Swardson   0.405738\n",
      "83       Gerard Butler   0.400810\n",
      "66      Rosario Dawson   0.396000\n",
      "1    Samuel L. Jackson   0.392857\n",
      "28     Bobby Cannavale   0.391304\n",
      "\n",
      "Top 10 por PageRank:\n",
      "               Actor  PageRank\n",
      "2   Takahiro Sakurai  0.022188\n",
      "27   Elizabeth Banks  0.021094\n",
      "25       Daisuke Ono  0.020180\n",
      "5          Yuki Kaji  0.019797\n",
      "17      Maya Rudolph  0.018389\n",
      "22      Adam Sandler  0.016935\n",
      "0        Anupam Kher  0.016835\n",
      "35     Molly Shannon  0.015881\n",
      "6     Shah Rukh Khan  0.015163\n",
      "4    Yuichi Nakamura  0.015064\n",
      "\n",
      "Etapa 4 conclu√≠da ‚Äî valide os resultados antes de prosseguirmos para as centralidades mais custosas (se necess√°rio) ou detec√ß√£o de comunidades.\n"
     ]
    }
   ],
   "source": [
    "# Etapa 4: Construir grafo NetworkX e calcular m√©tricas (densidade, centralidades, PageRank)\n",
    "# Esta c√©lula roda a an√°lise do grafo a partir de `filtered_pair_counts.pkl` e `top_actor_names.pkl`.\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir = root / 'results'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"Nomes no top: {len(top_names)}; pares filtrados: {len(filtered_pairs)}\")\n",
    "\n",
    "# Construir grafo ponderado (undirected)\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(top_names)\n",
    "for (a, b), w in filtered_pairs.items():\n",
    "    # adicionar aresta com atributo weight\n",
    "    G.add_edge(a, b, weight=w)\n",
    "\n",
    "n_nodes = G.number_of_nodes()\n",
    "n_edges = G.number_of_edges()\n",
    "print(f\"Grafo: n√≥s={n_nodes}, arestas={n_edges}\")\n",
    "\n",
    "# M√©tricas globais\n",
    "density = nx.density(G)\n",
    "components = list(nx.connected_components(G))\n",
    "num_components = len(components)\n",
    "largest_cc = max(components, key=len) if components else set()\n",
    "largest_cc_size = len(largest_cc)\n",
    "\n",
    "print(f\"Densidade: {density:.6g}\")\n",
    "print(f\"Componentes: {num_components}; maior componente: {largest_cc_size} n√≥s\")\n",
    "\n",
    "# Centralidades\n",
    "print('\\nCalculando centralidades... (isso pode levar algum tempo para betweenness se exato)')\n",
    "# Degree centrality (normalizada)\n",
    "degree_c = nx.degree_centrality(G)\n",
    "# Betweenness centrality (exata ou aproximada)\n",
    "betweenness_c = nx.betweenness_centrality(G)\n",
    "# Closeness centrality\n",
    "closeness_c = nx.closeness_centrality(G)\n",
    "# PageRank (usa weights)\n",
    "pagerank = nx.pagerank(G, alpha=0.85, max_iter=100)\n",
    "\n",
    "# Degree raw (n√∫mero de vizinhos)\n",
    "degree_raw = dict(G.degree())\n",
    "\n",
    "# Montar DataFrame com m√©tricas\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Actor': list(G.nodes()),\n",
    "    'Degree': [degree_raw.get(n, 0) for n in G.nodes()],\n",
    "    'DegreeCentrality': [degree_c.get(n, 0) for n in G.nodes()],\n",
    "    'Betweenness': [betweenness_c.get(n, 0) for n in G.nodes()],\n",
    "    'Closeness': [closeness_c.get(n, 0) for n in G.nodes()],\n",
    "    'PageRank': [pagerank.get(n, 0) for n in G.nodes()],\n",
    "})\n",
    "\n",
    "# Normalizar colunas (opcional) ‚Äî apenas como colunas separadas para inspe√ß√£o\n",
    "metrics_df['Degree_norm'] = (metrics_df['Degree'] - metrics_df['Degree'].min()) / (metrics_df['Degree'].max() - metrics_df['Degree'].min())\n",
    "metrics_df['Betweenness_norm'] = (metrics_df['Betweenness'] - metrics_df['Betweenness'].min()) / (metrics_df['Betweenness'].max() - metrics_df['Betweenness'].min())\n",
    "metrics_df['Closeness_norm'] = (metrics_df['Closeness'] - metrics_df['Closeness'].min()) / (metrics_df['Closeness'].max() - metrics_df['Closeness'].min())\n",
    "metrics_df['PageRank_norm'] = (metrics_df['PageRank'] - metrics_df['PageRank'].min()) / (metrics_df['PageRank'].max() - metrics_df['PageRank'].min())\n",
    "\n",
    "# Salvar resultados\n",
    "metrics_csv = out_dir / 'graph_metrics.csv'\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "# salvar grafo em gpickle\n",
    "\n",
    "\n",
    "# Mostrar top 10 por cada medida\n",
    "print(f\"\\nM√©tricas salvas em: {metrics_csv}\")\n",
    "\n",
    "print('\\nTop 10 por Degree:')\n",
    "print(metrics_df.sort_values('Degree', ascending=False).head(10)[['Actor','Degree']])\n",
    "print('\\nTop 10 por Betweenness:')\n",
    "print(metrics_df.sort_values('Betweenness', ascending=False).head(10)[['Actor','Betweenness']])\n",
    "print('\\nTop 10 por Closeness:')\n",
    "print(metrics_df.sort_values('Closeness', ascending=False).head(10)[['Actor','Closeness']])\n",
    "print('\\nTop 10 por PageRank:')\n",
    "print(metrics_df.sort_values('PageRank', ascending=False).head(10)[['Actor','PageRank']])\n",
    "\n",
    "# Guardar as vari√°veis no notebook para uso futuro\n",
    "G_graph = G\n",
    "filtered_pairs_graph = filtered_pairs\n",
    "metrics = metrics_df\n",
    "\n",
    "print('\\nEtapa 4 conclu√≠da ‚Äî valide os resultados antes de prosseguirmos para as centralidades mais custosas (se necess√°rio) ou detec√ß√£o de comunidades.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e3d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodando Louvain (NetworkX nativo) em n=100 n√≥s, m=583 arestas\n",
      "Par√¢metro de resolu√ß√£o: 1, seed: 42\n",
      "\n",
      "Modularidade obtida: 0.507\n",
      "N√∫mero de comunidades: 3\n",
      "\n",
      "Distribui√ß√£o de tamanhos (min=12, max=61, mean=33.3, median=27.0)\n",
      "\n",
      "================================================================================\n",
      "GERANDO ARQUIVOS PARA FLOURISH\n",
      "================================================================================\n",
      "\n",
      "‚úÖ links.csv gerado:\n",
      "   - 583 arestas\n",
      "   - Arquivo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_coautoria/links.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ points.csv gerado:\n",
      "   - 100 atores\n",
      "   - 3 comunidades\n",
      "   - Colunas: id, Community, Degree, Appearances, Betweenness, Closeness, PageRank\n",
      "   - Arquivo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_coautoria/points.csv\n",
      "\n",
      "================================================================================\n",
      "TOP 10 ATORES POR MEDIDA DE CENTRALIDADE\n",
      "================================================================================\n",
      "\n",
      "üîó Top 10 por Degree (n√∫mero de conex√µes):\n",
      "   5. Yuichi Nakamura: 27 conex√µes (filmes: 19)\n",
      "   3. Takahiro Sakurai: 26 conex√µes (filmes: 32)\n",
      "   6. Yuki Kaji: 25 conex√µes (filmes: 29)\n",
      "   11. Jun Fukuyama: 25 conex√µes (filmes: 16)\n",
      "   26. Daisuke Ono: 24 conex√µes (filmes: 22)\n",
      "   43. Ai Kayano: 23 conex√µes (filmes: 19)\n",
      "   44. Kana Hanazawa: 23 conex√µes (filmes: 18)\n",
      "   76. Nobuhiko Okamoto: 23 conex√µes (filmes: 12)\n",
      "   10. Katsuyuki Konishi: 22 conex√µes (filmes: 12)\n",
      "   13. Junichi Suwabe: 22 conex√µes (filmes: 21)\n",
      "\n",
      "üåâ Top 10 por Betweenness (intermedia√ß√£o):\n",
      "   31. Kari Wahlgren: 1.0000 (grau: 18, filmes: 16)\n",
      "   88. Chlo√´ Grace Moretz: 0.3857 (grau: 13, filmes: 9)\n",
      "   1. Anupam Kher: 0.3357 (grau: 13, filmes: 43)\n",
      "   90. Paul Giamatti: 0.2904 (grau: 13, filmes: 12)\n",
      "   4. Fred Tatasciore: 0.1894 (grau: 9, filmes: 23)\n",
      "   84. Gerard Butler: 0.1882 (grau: 14, filmes: 13)\n",
      "   65. Ben Kingsley: 0.1726 (grau: 4, filmes: 15)\n",
      "   21. Nick Swardson: 0.1566 (grau: 11, filmes: 12)\n",
      "   2. Samuel L. Jackson: 0.1506 (grau: 12, filmes: 24)\n",
      "   16. Hiroshi Kamiya: 0.1381 (grau: 20, filmes: 16)\n",
      "\n",
      "üìç Top 10 por Closeness (proximidade):\n",
      "   31. Kari Wahlgren: 1.0000 (grau: 18, filmes: 16)\n",
      "   88. Chlo√´ Grace Moretz: 0.9834 (grau: 13, filmes: 9)\n",
      "   90. Paul Giamatti: 0.8826 (grau: 13, filmes: 12)\n",
      "   4. Fred Tatasciore: 0.8467 (grau: 9, filmes: 23)\n",
      "   28. Elizabeth Banks: 0.8328 (grau: 21, filmes: 11)\n",
      "   21. Nick Swardson: 0.8190 (grau: 11, filmes: 12)\n",
      "   84. Gerard Butler: 0.7989 (grau: 14, filmes: 13)\n",
      "   67. Rosario Dawson: 0.7792 (grau: 5, filmes: 14)\n",
      "   2. Samuel L. Jackson: 0.7664 (grau: 12, filmes: 24)\n",
      "   29. Bobby Cannavale: 0.7600 (grau: 14, filmes: 11)\n",
      "\n",
      "‚≠ê Top 10 por PageRank (import√¢ncia):\n",
      "   3. Takahiro Sakurai: 1.0000 (grau: 26, filmes: 32)\n",
      "   28. Elizabeth Banks: 0.9420 (grau: 21, filmes: 11)\n",
      "   26. Daisuke Ono: 0.8935 (grau: 24, filmes: 22)\n",
      "   6. Yuki Kaji: 0.8732 (grau: 25, filmes: 29)\n",
      "   18. Maya Rudolph: 0.7985 (grau: 15, filmes: 16)\n",
      "   23. Adam Sandler: 0.7213 (grau: 10, filmes: 20)\n",
      "   1. Anupam Kher: 0.7160 (grau: 13, filmes: 43)\n",
      "   36. Molly Shannon: 0.6654 (grau: 13, filmes: 17)\n",
      "   7. Shah Rukh Khan: 0.6273 (grau: 8, filmes: 35)\n",
      "   5. Yuichi Nakamura: 0.6220 (grau: 27, filmes: 19)\n",
      "\n",
      "\n",
      " >>> Densidade do grafo de coautoria analisado: 0.117778 <<<\n",
      "\n",
      "================================================================================\n",
      "RESUMO DAS COMUNIDADES\n",
      "================================================================================\n",
      "\n",
      "Top 10 maiores comunidades (ID: tamanho):\n",
      "  1. Comunidade 2: 61 atores\n",
      "  2. Comunidade 1: 27 atores\n",
      "  3. Comunidade 0: 12 atores\n",
      "\n",
      "================================================================================\n",
      "ARQUIVOS FLOURISH PRONTOS!\n",
      "================================================================================\n",
      "\n",
      "üìÅ Diret√≥rio: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_coautoria\n",
      "   ‚îú‚îÄ‚îÄ links.csv    (583 arestas)\n",
      "   ‚îú‚îÄ‚îÄ points.csv   (100 n√≥s, 3 comunidades)\n",
      "   ‚îú‚îÄ‚îÄ louvain_stats.csv\n",
      "   ‚îî‚îÄ‚îÄ communities_louvain.pkl\n",
      "\n",
      "‚ú® Importe links.csv e points.csv no Flourish Network Graph!\n",
      "   - Use 'id' como node identifier\n",
      "   - Use 'Community' para colorir os n√≥s\n"
     ]
    }
   ],
   "source": [
    "# Etapa 6: Louvain + Gera√ß√£o de arquivos para Flourish\n",
    "# Detecta comunidades com Louvain e gera links.csv e points.csv para visualiza√ß√£o no Flourish\n",
    "\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "from networkx.algorithms.community.quality import modularity\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Par√¢metros ajust√°veis\n",
    "LOUVAIN_RESOLUTION = 1  # padr√£o 1.0; aumentar => mais comunidades\n",
    "USE_LARGEST_CC = True\n",
    "LOUVAIN_SEED = 42  # seed para reprodutibilidade\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir = root / 'results' / 'grafo_coautoria'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Carregar grafo se necess√°rio\n",
    "try:\n",
    "    G\n",
    "    filtered_pairs\n",
    "except NameError:\n",
    "    raise FileNotFoundError('Grafo n√£o encontrado. Execute a c√©lula que constr√≥i o grafo (Etapa 4) primeiro.')\n",
    "\n",
    "# Subgrafo onde rodar Louvain\n",
    "if USE_LARGEST_CC:\n",
    "    comps = list(nx.connected_components(G))\n",
    "    largest = max(comps, key=len)\n",
    "    G_louvain = G.subgraph(largest).copy()\n",
    "else:\n",
    "    G_louvain = G\n",
    "\n",
    "print(f\"Rodando Louvain (NetworkX nativo) em n={G_louvain.number_of_nodes()} n√≥s, m={G_louvain.number_of_edges()} arestas\")\n",
    "print(f\"Par√¢metro de resolu√ß√£o: {LOUVAIN_RESOLUTION}, seed: {LOUVAIN_SEED}\")\n",
    "\n",
    "# Executar Louvain (retorna lista de sets/frozensets)\n",
    "communities_sets = louvain_communities(G_louvain, weight='weight', resolution=LOUVAIN_RESOLUTION, seed=LOUVAIN_SEED)\n",
    "\n",
    "# Converter para lista de listas\n",
    "communities_list = [list(c) for c in communities_sets]\n",
    "\n",
    "# Calcular modularidade\n",
    "mod = modularity(G_louvain, communities_list, weight='weight')\n",
    "num_communities = len(communities_list)\n",
    "\n",
    "print(f\"\\nModularidade obtida: {mod:.3f}\")\n",
    "print(f\"N√∫mero de comunidades: {num_communities}\")\n",
    "\n",
    "# Estat√≠sticas das comunidades\n",
    "sizes = pd.Series([len(c) for c in communities_list])\n",
    "print(f\"\\nDistribui√ß√£o de tamanhos (min={sizes.min()}, max={sizes.max()}, mean={sizes.mean():.1f}, median={sizes.median():.1f})\")\n",
    "\n",
    "# Criar dicion√°rio node -> community_id\n",
    "partition = {}\n",
    "for cid, comm in enumerate(communities_list):\n",
    "    for node in comm:\n",
    "        partition[node] = cid\n",
    "\n",
    "# Estender parti√ß√£o para todos os n√≥s do grafo original\n",
    "comm_dict_louvain = {}\n",
    "for node in G.nodes():\n",
    "    if node in partition:\n",
    "        comm_dict_louvain[node] = partition[node]\n",
    "    else:\n",
    "        comm_dict_louvain[node] = -1  # N√≥s fora do maior componente\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO ARQUIVOS PARA FLOURISH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========== 1. GERAR links.csv ==========\n",
    "# Filtrar apenas arestas do subgrafo Louvain\n",
    "links_data = []\n",
    "for (a, b), weight in filtered_pairs.items():\n",
    "    # Incluir apenas se ambos est√£o no G_louvain\n",
    "    if a in G_louvain.nodes() and b in G_louvain.nodes():\n",
    "        links_data.append((a, b, weight))\n",
    "\n",
    "links_df = pd.DataFrame(links_data, columns=['Source', 'Target', 'Value'])\n",
    "links_csv = out_dir / 'links.csv'\n",
    "links_df.to_csv(links_csv, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ links.csv gerado:\")\n",
    "print(f\"   - {len(links_df)} arestas\")\n",
    "print(f\"   - Arquivo: {links_csv}\")\n",
    "\n",
    "# ========== 2. GERAR points.csv ==========\n",
    "# Calcular m√©tricas de centralidade para o subgrafo Louvain\n",
    "betweenness_louvain = nx.betweenness_centrality(G_louvain, weight='weight')\n",
    "closeness_louvain = nx.closeness_centrality(G_louvain)\n",
    "pagerank_louvain = nx.pagerank(G_louvain, weight='weight')\n",
    "\n",
    "# Normalizar m√©tricas (min-max normalization)\n",
    "betweenness_values = list(betweenness_louvain.values())\n",
    "closeness_values = list(closeness_louvain.values())\n",
    "pagerank_values = list(pagerank_louvain.values())\n",
    "\n",
    "betw_min, betw_max = min(betweenness_values), max(betweenness_values)\n",
    "clos_min, clos_max = min(closeness_values), max(closeness_values)\n",
    "pr_min, pr_max = min(pagerank_values), max(pagerank_values)\n",
    "\n",
    "points_data = []\n",
    "for actor in G_louvain.nodes():\n",
    "    # Normalizar valores\n",
    "    betw_norm = (betweenness_louvain[actor] - betw_min) / (betw_max - betw_min) if betw_max > betw_min else 0\n",
    "    clos_norm = (closeness_louvain[actor] - clos_min) / (clos_max - clos_min) if clos_max > clos_min else 0\n",
    "    pr_norm = (pagerank_louvain[actor] - pr_min) / (pr_max - pr_min) if pr_max > pr_min else 0\n",
    "    \n",
    "    points_data.append((\n",
    "        actor,  # id\n",
    "        comm_dict_louvain[actor],  # Community\n",
    "        G_louvain.degree(actor),  # Degree (n√∫mero de conex√µes)\n",
    "        actor_appearances.get(actor, 0),  # Appearances (total de filmes)\n",
    "        round(betw_norm, 4),  # Betweenness (normalizado)\n",
    "        round(clos_norm, 4),  # Closeness (normalizado)\n",
    "        round(pr_norm, 4)  # PageRank (normalizado)\n",
    "    ))\n",
    "\n",
    "points_df = pd.DataFrame(points_data, columns=['id', 'Community', 'Degree', 'Appearances', 'Betweenness', 'Closeness', 'PageRank'])\n",
    "points_csv = out_dir / 'points.csv'\n",
    "points_df.to_csv(points_csv, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ points.csv gerado:\")\n",
    "print(f\"   - {len(points_df)} atores\")\n",
    "print(f\"   - {points_df['Community'].nunique()} comunidades\")\n",
    "print(f\"   - Colunas: id, Community, Degree, Appearances, Betweenness, Closeness, PageRank\")\n",
    "print(f\"   - Arquivo: {points_csv}\")\n",
    "\n",
    "coauthors_density = nx.density(G_louvain)\n",
    "\n",
    "# ========== AN√ÅLISE: TOP 10 POR CENTRALIDADE ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 ATORES POR MEDIDA DE CENTRALIDADE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüîó Top 10 por Degree (n√∫mero de conex√µes):\")\n",
    "for idx, row in points_df.nlargest(10, 'Degree').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Degree']} conex√µes (filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\nüåâ Top 10 por Betweenness (intermedia√ß√£o):\")\n",
    "for idx, row in points_df.nlargest(10, 'Betweenness').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Betweenness']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\nüìç Top 10 por Closeness (proximidade):\")\n",
    "for idx, row in points_df.nlargest(10, 'Closeness').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Closeness']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\n‚≠ê Top 10 por PageRank (import√¢ncia):\")\n",
    "for idx, row in points_df.nlargest(10, 'PageRank').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['PageRank']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\n\\n >>> Densidade do grafo de coautoria analisado: {:.6g} <<<\".format(coauthors_density))\n",
    "\n",
    "# ========== 3. SALVAR METADADOS ==========\n",
    "# Salvar stats de Louvain\n",
    "louvain_stats = {\n",
    "    'resolution': LOUVAIN_RESOLUTION,\n",
    "    'seed': LOUVAIN_SEED,\n",
    "    'modularity': mod,\n",
    "    'num_communities': num_communities,\n",
    "    'nodes_analyzed': G_louvain.number_of_nodes(),\n",
    "    'edges_analyzed': G_louvain.number_of_edges()\n",
    "}\n",
    "\n",
    "pd.DataFrame([louvain_stats]).to_csv(out_dir / 'louvain_stats.csv', index=False)\n",
    "\n",
    "# Salvar parti√ß√£o em pickle\n",
    "with open(out_dir / 'communities_louvain.pkl', 'wb') as f:\n",
    "    pickle.dump(comm_dict_louvain, f)\n",
    "\n",
    "# ========== 4. RESUMO DAS COMUNIDADES ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO DAS COMUNIDADES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comm_sizes = points_df['Community'].value_counts().sort_values(ascending=False)\n",
    "print(f\"\\nTop 10 maiores comunidades (ID: tamanho):\")\n",
    "for idx, (comm_id, size) in enumerate(comm_sizes.head(10).items(), 1):\n",
    "    print(f\"  {idx}. Comunidade {comm_id}: {size} atores\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARQUIVOS FLOURISH PRONTOS!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÅ Diret√≥rio: {out_dir}\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ links.csv    ({len(links_df)} arestas)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ points.csv   ({len(points_df)} n√≥s, {num_communities} comunidades)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ louvain_stats.csv\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ communities_louvain.pkl\")\n",
    "print(\"\\n‚ú® Importe links.csv e points.csv no Flourish Network Graph!\")\n",
    "print(\"   - Use 'id' como node identifier\")\n",
    "print(\"   - Use 'Community' para colorir os n√≥s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e6bd90",
   "metadata": {},
   "source": [
    "# Atores com mais filmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e10d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atores dispon√≠veis: 36439, selecionando TOP_N_APPEARANCES = 100 => selecionados: 100\n",
      "Pares no subgrafo dos TOP 100 (por apari√ß√µes): 460\n",
      "\n",
      "Top 10 (dos selecionados) por apari√ß√µes:\n",
      "Anupam Kher: 43 filmes, grau=273\n",
      "Shah Rukh Khan: 35 filmes, grau=210\n",
      "Julie Tejwani: 33 filmes, grau=37\n",
      "Naseeruddin Shah: 32 filmes, grau=183\n",
      "Takahiro Sakurai: 32 filmes, grau=228\n",
      "Rupa Bhimani: 31 filmes, grau=28\n",
      "Akshay Kumar: 30 filmes, grau=193\n",
      "Om Puri: 30 filmes, grau=187\n",
      "Yuki Kaji: 29 filmes, grau=220\n",
      "Amitabh Bachchan: 28 filmes, grau=178\n",
      "\n",
      "‚úÖ Sele√ß√£o por apari√ß√µes conclu√≠da. Pr√≥ximo: construir grafo e calcular m√©tricas.\n"
     ]
    }
   ],
   "source": [
    "# Etapa 7: Selecionar TOP_N atores por APARI√á√ïES (n√∫mero de filmes)\n",
    "# Crit√©rio diferente do grafo de coautoria (que usa grau/conex√µes)\n",
    "\n",
    "# Par√¢metro din√¢mico: altere antes de executar, se desejar\n",
    "TOP_N_APPEARANCES = 100\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "\n",
    "# Validar que temos os dados necess√°rios\n",
    "try:\n",
    "    actor_coactors\n",
    "    pair_counts\n",
    "    actor_appearances\n",
    "except NameError:\n",
    "    raise FileNotFoundError('Estruturas de parsing n√£o encontradas. Execute a c√©lula de parsing (Etapa 2) primeiro.')\n",
    "\n",
    "# Selecionar TOP_N por n√∫mero de apari√ß√µes (filmes)\n",
    "sorted_by_appearances = sorted(actor_appearances.items(), key=lambda x: x[1], reverse=True)\n",
    "top_actors_appearances = sorted_by_appearances[:TOP_N_APPEARANCES]\n",
    "actual_top_n_appearances = len(top_actors_appearances)\n",
    "\n",
    "print(f\"Atores dispon√≠veis: {len(actor_appearances)}, selecionando TOP_N_APPEARANCES = {TOP_N_APPEARANCES} => selecionados: {actual_top_n_appearances}\")\n",
    "\n",
    "top_names_appearances = [a for a, _ in top_actors_appearances]\n",
    "top_set_appearances = set(top_names_appearances)\n",
    "\n",
    "# Filtrar pares onde ambos est√£o no top (por apari√ß√µes)\n",
    "filtered_pairs_appearances = {pair: cnt for pair, cnt in pair_counts.items() \n",
    "                              if pair[0] in top_set_appearances and pair[1] in top_set_appearances}\n",
    "num_filtered_pairs_appearances = len(filtered_pairs_appearances)\n",
    "\n",
    "print(f\"Pares no subgrafo dos TOP {actual_top_n_appearances} (por apari√ß√µes): {num_filtered_pairs_appearances}\")\n",
    "\n",
    "# Resumo r√°pido dos 10 atores com mais filmes selecionados\n",
    "print(f'\\nTop 10 (dos selecionados) por apari√ß√µes:')\n",
    "for actor, apps in top_actors_appearances[:10]:\n",
    "    # Calcular grau (conex√µes) para compara√ß√£o\n",
    "    degree = len(actor_coactors.get(actor, set()))\n",
    "    print(f\"{actor}: {apps} filmes, grau={degree}\")\n",
    "\n",
    "print(f'\\n‚úÖ Sele√ß√£o por apari√ß√µes conclu√≠da. Pr√≥ximo: construir grafo e calcular m√©tricas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09d13f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomes no top (por apari√ß√µes): 100; pares filtrados: 460\n",
      "Grafo: n√≥s=100, arestas=460\n",
      "Densidade: 0.0929293\n",
      "Componentes: 9; maior componente: 82 n√≥s\n",
      "\n",
      "Calculando centralidades... (isso pode levar algum tempo para betweenness se exato)\n",
      "\n",
      "M√©tricas salvas em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_atores_mais_filmes/graph_metrics.csv\n",
      "\n",
      "Top 10 por Degree:\n",
      "               Actor  Degree\n",
      "0        Anupam Kher      26\n",
      "11       Boman Irani      24\n",
      "7            Om Puri      22\n",
      "1     Shah Rukh Khan      22\n",
      "15    Kareena Kapoor      21\n",
      "52      Rajpal Yadav      21\n",
      "59     Jackie Shroff      20\n",
      "9   Amitabh Bachchan      20\n",
      "10      Paresh Rawal      19\n",
      "48       Anil Kapoor      19\n",
      "\n",
      "Top 10 por Betweenness:\n",
      "              Actor  Betweenness\n",
      "0       Anupam Kher     0.300174\n",
      "90     Willem Dafoe     0.173630\n",
      "19  Fred Tatasciore     0.147288\n",
      "97      Keith David     0.145079\n",
      "74    Alfred Molina     0.137690\n",
      "66    Kari Wahlgren     0.112241\n",
      "53   Brian Drummond     0.097888\n",
      "31      David Spade     0.069610\n",
      "20      Tara Strong     0.064459\n",
      "47     Laura Bailey     0.053064\n",
      "\n",
      "Top 10 por Closeness:\n",
      "               Actor  Closeness\n",
      "97       Keith David   0.305404\n",
      "0        Anupam Kher   0.304003\n",
      "90      Willem Dafoe   0.302615\n",
      "19   Fred Tatasciore   0.290670\n",
      "74     Alfred Molina   0.289401\n",
      "53    Brian Drummond   0.270501\n",
      "66     Kari Wahlgren   0.265091\n",
      "47      Laura Bailey   0.264035\n",
      "86      Grey Griffin   0.258878\n",
      "9   Amitabh Bachchan   0.251988\n",
      "\n",
      "Top 10 por PageRank:\n",
      "               Actor  PageRank\n",
      "31       David Spade  0.024698\n",
      "0        Anupam Kher  0.022719\n",
      "14     Andrea Libman  0.018635\n",
      "6       Akshay Kumar  0.018499\n",
      "1     Shah Rukh Khan  0.018315\n",
      "4   Takahiro Sakurai  0.017977\n",
      "21       Daisuke Ono  0.017257\n",
      "8          Yuki Kaji  0.016776\n",
      "11       Boman Irani  0.016745\n",
      "10      Paresh Rawal  0.016452\n",
      "\n",
      "‚úÖ Etapa 8 conclu√≠da ‚Äî m√©tricas calculadas para o grafo de atores com mais filmes.\n"
     ]
    }
   ],
   "source": [
    "# Etapa 8: Construir grafo NetworkX e calcular m√©tricas (Grafo por Apari√ß√µes)\n",
    "# Mesma an√°lise do grafo de coautoria, mas com atores selecionados por n√∫mero de filmes\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir_appearances = root / 'results' / 'grafo_atores_mais_filmes'\n",
    "out_dir_appearances.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Nomes no top (por apari√ß√µes): {len(top_names_appearances)}; pares filtrados: {len(filtered_pairs_appearances)}\")\n",
    "\n",
    "# Construir grafo ponderado (undirected)\n",
    "G_appearances = nx.Graph()\n",
    "G_appearances.add_nodes_from(top_names_appearances)\n",
    "for (a, b), w in filtered_pairs_appearances.items():\n",
    "    # adicionar aresta com atributo weight\n",
    "    G_appearances.add_edge(a, b, weight=w)\n",
    "\n",
    "n_nodes_app = G_appearances.number_of_nodes()\n",
    "n_edges_app = G_appearances.number_of_edges()\n",
    "print(f\"Grafo: n√≥s={n_nodes_app}, arestas={n_edges_app}\")\n",
    "\n",
    "# M√©tricas globais\n",
    "density_app = nx.density(G_appearances)\n",
    "components_app = list(nx.connected_components(G_appearances))\n",
    "num_components_app = len(components_app)\n",
    "largest_cc_app = max(components_app, key=len) if components_app else set()\n",
    "largest_cc_size_app = len(largest_cc_app)\n",
    "\n",
    "print(f\"Densidade: {density_app:.6g}\")\n",
    "print(f\"Componentes: {num_components_app}; maior componente: {largest_cc_size_app} n√≥s\")\n",
    "\n",
    "# Centralidades\n",
    "print('\\nCalculando centralidades... (isso pode levar algum tempo para betweenness se exato)')\n",
    "# Degree centrality (normalizada)\n",
    "degree_c_app = nx.degree_centrality(G_appearances)\n",
    "# Betweenness centrality (exata ou aproximada)\n",
    "betweenness_c_app = nx.betweenness_centrality(G_appearances)\n",
    "# Closeness centrality\n",
    "closeness_c_app = nx.closeness_centrality(G_appearances)\n",
    "# PageRank (usa weights)\n",
    "pagerank_app = nx.pagerank(G_appearances, alpha=0.85, max_iter=100)\n",
    "\n",
    "# Degree raw (n√∫mero de vizinhos)\n",
    "degree_raw_app = dict(G_appearances.degree())\n",
    "\n",
    "# Montar DataFrame com m√©tricas\n",
    "metrics_df_app = pd.DataFrame({\n",
    "    'Actor': list(G_appearances.nodes()),\n",
    "    'Degree': [degree_raw_app.get(n, 0) for n in G_appearances.nodes()],\n",
    "    'DegreeCentrality': [degree_c_app.get(n, 0) for n in G_appearances.nodes()],\n",
    "    'Betweenness': [betweenness_c_app.get(n, 0) for n in G_appearances.nodes()],\n",
    "    'Closeness': [closeness_c_app.get(n, 0) for n in G_appearances.nodes()],\n",
    "    'PageRank': [pagerank_app.get(n, 0) for n in G_appearances.nodes()],\n",
    "})\n",
    "\n",
    "# Normalizar colunas (opcional) ‚Äî apenas como colunas separadas para inspe√ß√£o\n",
    "metrics_df_app['Degree_norm'] = (metrics_df_app['Degree'] - metrics_df_app['Degree'].min()) / (metrics_df_app['Degree'].max() - metrics_df_app['Degree'].min())\n",
    "metrics_df_app['Betweenness_norm'] = (metrics_df_app['Betweenness'] - metrics_df_app['Betweenness'].min()) / (metrics_df_app['Betweenness'].max() - metrics_df_app['Betweenness'].min())\n",
    "metrics_df_app['Closeness_norm'] = (metrics_df_app['Closeness'] - metrics_df_app['Closeness'].min()) / (metrics_df_app['Closeness'].max() - metrics_df_app['Closeness'].min())\n",
    "metrics_df_app['PageRank_norm'] = (metrics_df_app['PageRank'] - metrics_df_app['PageRank'].min()) / (metrics_df_app['PageRank'].max() - metrics_df_app['PageRank'].min())\n",
    "\n",
    "# Salvar resultados\n",
    "metrics_csv_app = out_dir_appearances / 'graph_metrics.csv'\n",
    "metrics_df_app.to_csv(metrics_csv_app, index=False)\n",
    "\n",
    "# Mostrar top 10 por cada medida\n",
    "print(f\"\\nM√©tricas salvas em: {metrics_csv_app}\")\n",
    "\n",
    "print('\\nTop 10 por Degree:')\n",
    "print(metrics_df_app.sort_values('Degree', ascending=False).head(10)[['Actor','Degree']])\n",
    "print('\\nTop 10 por Betweenness:')\n",
    "print(metrics_df_app.sort_values('Betweenness', ascending=False).head(10)[['Actor','Betweenness']])\n",
    "print('\\nTop 10 por Closeness:')\n",
    "print(metrics_df_app.sort_values('Closeness', ascending=False).head(10)[['Actor','Closeness']])\n",
    "print('\\nTop 10 por PageRank:')\n",
    "print(metrics_df_app.sort_values('PageRank', ascending=False).head(10)[['Actor','PageRank']])\n",
    "\n",
    "print('\\n‚úÖ Etapa 8 conclu√≠da ‚Äî m√©tricas calculadas para o grafo de atores com mais filmes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe76ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodando Louvain (NetworkX nativo) em n=100 n√≥s, m=460 arestas\n",
      "Par√¢metro de resolu√ß√£o: 1, seed: 42\n",
      "\n",
      "Modularidade obtida: 0.763\n",
      "N√∫mero de comunidades: 13\n",
      "\n",
      "Distribui√ß√£o de tamanhos (min=1, max=32, mean=7.7, median=4.0)\n",
      "\n",
      "================================================================================\n",
      "GERANDO ARQUIVOS PARA FLOURISH (ATORES COM MAIS FILMES)\n",
      "================================================================================\n",
      "\n",
      "‚úÖ links.csv gerado:\n",
      "   - 460 arestas\n",
      "   - Arquivo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_atores_mais_filmes/links.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ points.csv gerado:\n",
      "   - 100 atores\n",
      "   - 13 comunidades\n",
      "   - Colunas: id, Community, Degree, Appearances, Betweenness, Closeness, PageRank\n",
      "   - Arquivo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_atores_mais_filmes/points.csv\n",
      "\n",
      "================================================================================\n",
      "TOP 10 ATORES POR MEDIDA DE CENTRALIDADE\n",
      "================================================================================\n",
      "\n",
      "üîó Top 10 por Degree (n√∫mero de conex√µes):\n",
      "   1. Anupam Kher: 26 conex√µes (filmes: 43)\n",
      "   12. Boman Irani: 24 conex√µes (filmes: 27)\n",
      "   2. Shah Rukh Khan: 22 conex√µes (filmes: 35)\n",
      "   8. Om Puri: 22 conex√µes (filmes: 30)\n",
      "   16. Kareena Kapoor: 21 conex√µes (filmes: 25)\n",
      "   53. Rajpal Yadav: 21 conex√µes (filmes: 17)\n",
      "   10. Amitabh Bachchan: 20 conex√µes (filmes: 28)\n",
      "   60. Jackie Shroff: 20 conex√µes (filmes: 17)\n",
      "   7. Akshay Kumar: 19 conex√µes (filmes: 30)\n",
      "   11. Paresh Rawal: 19 conex√µes (filmes: 28)\n",
      "\n",
      "üåâ Top 10 por Betweenness (intermedia√ß√£o):\n",
      "   1. Anupam Kher: 1.0000 (grau: 26, filmes: 43)\n",
      "   91. Willem Dafoe: 0.6109 (grau: 5, filmes: 15)\n",
      "   67. Kari Wahlgren: 0.5930 (grau: 11, filmes: 16)\n",
      "   20. Fred Tatasciore: 0.5472 (grau: 6, filmes: 23)\n",
      "   98. Keith David: 0.5421 (grau: 6, filmes: 15)\n",
      "   75. Alfred Molina: 0.4507 (grau: 3, filmes: 16)\n",
      "   32. David Spade: 0.2913 (grau: 9, filmes: 19)\n",
      "   54. Brian Drummond: 0.2669 (grau: 11, filmes: 17)\n",
      "   21. Tara Strong: 0.2527 (grau: 8, filmes: 23)\n",
      "   35. Mamoru Miyano: 0.2337 (grau: 16, filmes: 19)\n",
      "\n",
      "üìç Top 10 por Closeness (proximidade):\n",
      "   98. Keith David: 1.0000 (grau: 6, filmes: 15)\n",
      "   1. Anupam Kher: 0.9954 (grau: 26, filmes: 43)\n",
      "   91. Willem Dafoe: 0.9909 (grau: 5, filmes: 15)\n",
      "   20. Fred Tatasciore: 0.9518 (grau: 6, filmes: 23)\n",
      "   75. Alfred Molina: 0.9476 (grau: 3, filmes: 16)\n",
      "   54. Brian Drummond: 0.8857 (grau: 11, filmes: 17)\n",
      "   67. Kari Wahlgren: 0.8680 (grau: 11, filmes: 16)\n",
      "   48. Laura Bailey: 0.8645 (grau: 8, filmes: 18)\n",
      "   87. Grey Griffin: 0.8477 (grau: 4, filmes: 15)\n",
      "   10. Amitabh Bachchan: 0.8251 (grau: 20, filmes: 28)\n",
      "\n",
      "‚≠ê Top 10 por PageRank (import√¢ncia):\n",
      "   32. David Spade: 1.0000 (grau: 9, filmes: 19)\n",
      "   1. Anupam Kher: 0.9145 (grau: 26, filmes: 43)\n",
      "   15. Andrea Libman: 0.7379 (grau: 9, filmes: 25)\n",
      "   7. Akshay Kumar: 0.7320 (grau: 19, filmes: 30)\n",
      "   2. Shah Rukh Khan: 0.7241 (grau: 22, filmes: 35)\n",
      "   5. Takahiro Sakurai: 0.7094 (grau: 13, filmes: 32)\n",
      "   22. Daisuke Ono: 0.6783 (grau: 14, filmes: 22)\n",
      "   9. Yuki Kaji: 0.6575 (grau: 14, filmes: 29)\n",
      "   12. Boman Irani: 0.6562 (grau: 24, filmes: 27)\n",
      "   11. Paresh Rawal: 0.6435 (grau: 19, filmes: 28)\n",
      "\n",
      "\n",
      " >>> Densidade do grafo de atores com mais filmes analisado: 0.0929293 <<<\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISE DETALHADA DAS COMUNIDADES\n",
      "================================================================================\n",
      "\n",
      "Top 10 maiores comunidades:\n",
      "  Comunidade 0: 32 atores | M√©dia: 21.1 filmes | Top: Anupam Kher (43 filmes)\n",
      "  Comunidade 5: 18 atores | M√©dia: 17.5 filmes | Top: Samuel L. Jackson (24 filmes)\n",
      "  Comunidade 6: 15 atores | M√©dia: 19.3 filmes | Top: Takahiro Sakurai (32 filmes)\n",
      "  Comunidade 1: 10 atores | M√©dia: 19.3 filmes | Top: Vincent Tong (26 filmes)\n",
      "  Comunidade 12: 7 atores | M√©dia: 17.9 filmes | Top: Fred Tatasciore (23 filmes)\n",
      "  Comunidade 3: 6 atores | M√©dia: 24.3 filmes | Top: Julie Tejwani (33 filmes)\n",
      "  Comunidade 2: 4 atores | M√©dia: 19.5 filmes | Top: John Cleese (24 filmes)\n",
      "  Comunidade 8: 3 atores | M√©dia: 15.3 filmes | Top: Blossom Chukwujekwu (16 filmes)\n",
      "  Comunidade 4: 1 atores | M√©dia: 20.0 filmes | Top: David Attenborough (20 filmes)\n",
      "  Comunidade 7: 1 atores | M√©dia: 17.0 filmes | Top: Michela Luci (17 filmes)\n",
      "  Comunidade 9: 1 atores | M√©dia: 16.0 filmes | Top: Kristen Stewart (16 filmes)\n",
      "  Comunidade 10: 1 atores | M√©dia: 16.0 filmes | Top: Hassan Hosny (16 filmes)\n",
      "  Comunidade 11: 1 atores | M√©dia: 16.0 filmes | Top: Robb Wells (16 filmes)\n",
      "\n",
      "================================================================================\n",
      "ARQUIVOS FLOURISH PRONTOS!\n",
      "================================================================================\n",
      "\n",
      "üìÅ Diret√≥rio: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_atores_mais_filmes\n",
      "   ‚îú‚îÄ‚îÄ links.csv              (460 arestas)\n",
      "   ‚îú‚îÄ‚îÄ points.csv             (100 n√≥s, 13 comunidades)\n",
      "   ‚îú‚îÄ‚îÄ graph_metrics.csv      (m√©tricas NetworkX)\n",
      "   ‚îú‚îÄ‚îÄ louvain_stats.csv      (estat√≠sticas Louvain)\n",
      "   ‚îú‚îÄ‚îÄ community_analysis.csv (an√°lise detalhada por comunidade)\n",
      "   ‚îî‚îÄ‚îÄ communities_louvain.pkl\n",
      "\n",
      "‚ú® Importe links.csv e points.csv no Flourish Network Graph!\n",
      "   - Use 'id' como node identifier\n",
      "   - Use 'Community' para colorir os n√≥s\n",
      "   - Use 'Appearances' para tamanho dos n√≥s\n"
     ]
    }
   ],
   "source": [
    "# Etapa 9: Louvain + Gera√ß√£o de arquivos para Flourish (Grafo por Apari√ß√µes)\n",
    "# Detecta comunidades com Louvain e gera links.csv e points.csv para visualiza√ß√£o no Flourish\n",
    "\n",
    "# Par√¢metros ajust√°veis\n",
    "LOUVAIN_RESOLUTION_APP = 1  # padr√£o 1.0; aumentar => mais comunidades\n",
    "USE_LARGEST_CC_APP = False\n",
    "LOUVAIN_SEED_APP = 42  # seed para reprodutibilidade\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir_app = root / 'results' / 'grafo_atores_mais_filmes'\n",
    "out_dir_app.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Carregar grafo se necess√°rio\n",
    "try:\n",
    "    G_appearances\n",
    "    filtered_pairs_appearances\n",
    "except NameError:\n",
    "    raise FileNotFoundError('Grafo n√£o encontrado. Execute a c√©lula que constr√≥i o grafo (Etapa 8) primeiro.')\n",
    "\n",
    "# Subgrafo onde rodar Louvain\n",
    "if USE_LARGEST_CC_APP:\n",
    "    comps_app = list(nx.connected_components(G_appearances))\n",
    "    largest_app = max(comps_app, key=len)\n",
    "    G_louvain_app = G_appearances.subgraph(largest_app).copy()\n",
    "else:\n",
    "    G_louvain_app = G_appearances\n",
    "\n",
    "print(f\"Rodando Louvain (NetworkX nativo) em n={G_louvain_app.number_of_nodes()} n√≥s, m={G_louvain_app.number_of_edges()} arestas\")\n",
    "print(f\"Par√¢metro de resolu√ß√£o: {LOUVAIN_RESOLUTION_APP}, seed: {LOUVAIN_SEED_APP}\")\n",
    "\n",
    "# Calcular densidade do subgrafo Louvain\n",
    "density_louvain_app = nx.density(G_louvain_app)\n",
    "\n",
    "# Executar Louvain (retorna lista de sets/frozensets)\n",
    "communities_sets_app = louvain_communities(G_louvain_app, weight='weight', resolution=LOUVAIN_RESOLUTION_APP, seed=LOUVAIN_SEED_APP)\n",
    "\n",
    "# Converter para lista de listas\n",
    "communities_list_app = [list(c) for c in communities_sets_app]\n",
    "\n",
    "# Calcular modularidade\n",
    "mod_app = modularity(G_louvain_app, communities_list_app, weight='weight')\n",
    "num_communities_app = len(communities_list_app)\n",
    "\n",
    "print(f\"\\nModularidade obtida: {mod_app:.3f}\")\n",
    "print(f\"N√∫mero de comunidades: {num_communities_app}\")\n",
    "\n",
    "# Estat√≠sticas das comunidades\n",
    "sizes_app = pd.Series([len(c) for c in communities_list_app])\n",
    "print(f\"\\nDistribui√ß√£o de tamanhos (min={sizes_app.min()}, max={sizes_app.max()}, mean={sizes_app.mean():.1f}, median={sizes_app.median():.1f})\")\n",
    "\n",
    "# Criar dicion√°rio node -> community_id\n",
    "partition_app = {}\n",
    "for cid, comm in enumerate(communities_list_app):\n",
    "    for node in comm:\n",
    "        partition_app[node] = cid\n",
    "\n",
    "# Estender parti√ß√£o para todos os n√≥s do grafo original\n",
    "comm_dict_louvain_app = {}\n",
    "for node in G_appearances.nodes():\n",
    "    if node in partition_app:\n",
    "        comm_dict_louvain_app[node] = partition_app[node]\n",
    "    else:\n",
    "        comm_dict_louvain_app[node] = -1  # N√≥s fora do maior componente\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO ARQUIVOS PARA FLOURISH (ATORES COM MAIS FILMES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========== 1. GERAR links.csv ==========\n",
    "# Filtrar apenas arestas do subgrafo Louvain\n",
    "links_data_app = []\n",
    "for (a, b), weight in filtered_pairs_appearances.items():\n",
    "    # Incluir apenas se ambos est√£o no G_louvain_app\n",
    "    if a in G_louvain_app.nodes() and b in G_louvain_app.nodes():\n",
    "        links_data_app.append((a, b, weight))\n",
    "\n",
    "links_df_app = pd.DataFrame(links_data_app, columns=['Source', 'Target', 'Value'])\n",
    "links_csv_app = out_dir_app / 'links.csv'\n",
    "links_df_app.to_csv(links_csv_app, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ links.csv gerado:\")\n",
    "print(f\"   - {len(links_df_app)} arestas\")\n",
    "print(f\"   - Arquivo: {links_csv_app}\")\n",
    "\n",
    "# ========== 2. GERAR points.csv ==========\n",
    "# Calcular m√©tricas de centralidade para o subgrafo Louvain\n",
    "betweenness_louvain_app = nx.betweenness_centrality(G_louvain_app, weight='weight')\n",
    "closeness_louvain_app = nx.closeness_centrality(G_louvain_app)\n",
    "pagerank_louvain_app = nx.pagerank(G_louvain_app, weight='weight')\n",
    "\n",
    "# Normalizar m√©tricas (min-max normalization)\n",
    "betweenness_values_app = list(betweenness_louvain_app.values())\n",
    "closeness_values_app = list(closeness_louvain_app.values())\n",
    "pagerank_values_app = list(pagerank_louvain_app.values())\n",
    "\n",
    "betw_min_app, betw_max_app = min(betweenness_values_app), max(betweenness_values_app)\n",
    "clos_min_app, clos_max_app = min(closeness_values_app), max(closeness_values_app)\n",
    "pr_min_app, pr_max_app = min(pagerank_values_app), max(pagerank_values_app)\n",
    "\n",
    "points_data_app = []\n",
    "for actor in G_louvain_app.nodes():\n",
    "    # Normalizar valores\n",
    "    betw_norm_app = (betweenness_louvain_app[actor] - betw_min_app) / (betw_max_app - betw_min_app) if betw_max_app > betw_min_app else 0\n",
    "    clos_norm_app = (closeness_louvain_app[actor] - clos_min_app) / (clos_max_app - clos_min_app) if clos_max_app > clos_min_app else 0\n",
    "    pr_norm_app = (pagerank_louvain_app[actor] - pr_min_app) / (pr_max_app - pr_min_app) if pr_max_app > pr_min_app else 0\n",
    "    \n",
    "    points_data_app.append((\n",
    "        actor,  # id\n",
    "        comm_dict_louvain_app[actor],  # Community\n",
    "        G_louvain_app.degree(actor),  # Degree (n√∫mero de conex√µes)\n",
    "        actor_appearances.get(actor, 0),  # Appearances (total de filmes)\n",
    "        round(betw_norm_app, 4),  # Betweenness (normalizado)\n",
    "        round(clos_norm_app, 4),  # Closeness (normalizado)\n",
    "        round(pr_norm_app, 4)  # PageRank (normalizado)\n",
    "    ))\n",
    "\n",
    "points_df_app = pd.DataFrame(points_data_app, columns=['id', 'Community', 'Degree', 'Appearances', 'Betweenness', 'Closeness', 'PageRank'])\n",
    "points_csv_app = out_dir_app / 'points.csv'\n",
    "points_df_app.to_csv(points_csv_app, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ points.csv gerado:\")\n",
    "print(f\"   - {len(points_df_app)} atores\")\n",
    "print(f\"   - {points_df_app['Community'].nunique()} comunidades\")\n",
    "print(f\"   - Colunas: id, Community, Degree, Appearances, Betweenness, Closeness, PageRank\")\n",
    "print(f\"   - Arquivo: {points_csv_app}\")\n",
    "\n",
    "    # ========== AN√ÅLISE: TOP 10 POR CENTRALIDADE ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 ATORES POR MEDIDA DE CENTRALIDADE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüîó Top 10 por Degree (n√∫mero de conex√µes):\")\n",
    "for idx, row in points_df_app.nlargest(10, 'Degree').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Degree']} conex√µes (filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\nüåâ Top 10 por Betweenness (intermedia√ß√£o):\")\n",
    "for idx, row in points_df_app.nlargest(10, 'Betweenness').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Betweenness']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\nüìç Top 10 por Closeness (proximidade):\")\n",
    "for idx, row in points_df_app.nlargest(10, 'Closeness').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Closeness']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\n‚≠ê Top 10 por PageRank (import√¢ncia):\")\n",
    "for idx, row in points_df_app.nlargest(10, 'PageRank').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['PageRank']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\n\\n >>> Densidade do grafo de atores com mais filmes analisado: {:.6g} <<<\".format(density_louvain_app))\n",
    "\n",
    "# ========== 3. SALVAR METADADOS ==========\n",
    "# Salvar stats de Louvain\n",
    "louvain_stats_app = {\n",
    "    'resolution': LOUVAIN_RESOLUTION_APP,\n",
    "    'seed': LOUVAIN_SEED_APP,\n",
    "    'modularity': mod_app,\n",
    "    'num_communities': num_communities_app,\n",
    "    'nodes_analyzed': G_louvain_app.number_of_nodes(),\n",
    "    'edges_analyzed': G_louvain_app.number_of_edges()\n",
    "}\n",
    "\n",
    "pd.DataFrame([louvain_stats_app]).to_csv(out_dir_app / 'louvain_stats.csv', index=False)\n",
    "\n",
    "# Salvar parti√ß√£o em pickle\n",
    "with open(out_dir_app / 'communities_louvain.pkl', 'wb') as f:\n",
    "    pickle.dump(comm_dict_louvain_app, f)\n",
    "\n",
    "# ========== 4. AN√ÅLISE DETALHADA DAS COMUNIDADES ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISE DETALHADA DAS COMUNIDADES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Estat√≠sticas por comunidade\n",
    "community_stats = []\n",
    "for comm_id in sorted(set(partition_app.values())):\n",
    "    members = [actor for actor in G_louvain_app.nodes() if partition_app.get(actor) == comm_id]\n",
    "    \n",
    "    # M√©tricas da comunidade\n",
    "    total_actors = len(members)\n",
    "    total_appearances = sum(actor_appearances.get(actor, 0) for actor in members)\n",
    "    avg_appearances = total_appearances / total_actors if total_actors > 0 else 0\n",
    "    \n",
    "    # Ator mais prol√≠fico da comunidade\n",
    "    top_actor = max(members, key=lambda a: actor_appearances.get(a, 0))\n",
    "    top_actor_apps = actor_appearances.get(top_actor, 0)\n",
    "    \n",
    "    community_stats.append({\n",
    "        'Community_ID': comm_id,\n",
    "        'Size': total_actors,\n",
    "        'Total_Appearances': total_appearances,\n",
    "        'Avg_Appearances': avg_appearances,\n",
    "        'Top_Actor': top_actor,\n",
    "        'Top_Actor_Appearances': top_actor_apps\n",
    "    })\n",
    "\n",
    "community_stats_df = pd.DataFrame(community_stats)\n",
    "community_stats_df.to_csv(out_dir_app / 'community_analysis.csv', index=False)\n",
    "\n",
    "# Exibir resumo\n",
    "print(f\"\\nTop 10 maiores comunidades:\")\n",
    "for idx, row in community_stats_df.nlargest(13, 'Size').iterrows():\n",
    "    print(f\"  Comunidade {row['Community_ID']}: {row['Size']} atores | \"\n",
    "          f\"M√©dia: {row['Avg_Appearances']:.1f} filmes | \"\n",
    "          f\"Top: {row['Top_Actor']} ({row['Top_Actor_Appearances']} filmes)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARQUIVOS FLOURISH PRONTOS!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÅ Diret√≥rio: {out_dir_app}\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ links.csv              ({len(links_df_app)} arestas)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ points.csv             ({len(points_df_app)} n√≥s, {num_communities_app} comunidades)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ graph_metrics.csv      (m√©tricas NetworkX)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ louvain_stats.csv      (estat√≠sticas Louvain)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ community_analysis.csv (an√°lise detalhada por comunidade)\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ communities_louvain.pkl\")\n",
    "print(\"\\n‚ú® Importe links.csv e points.csv no Flourish Network Graph!\")\n",
    "print(\"   - Use 'id' como node identifier\")\n",
    "print(\"   - Use 'Community' para colorir os n√≥s\")\n",
    "print(\"   - Use 'Appearances' para tamanho dos n√≥s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89673776",
   "metadata": {},
   "source": [
    "# Diretores com mais filmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba290c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas no CSV: 8807\n",
      "Diretores com pelo menos 1 co-diretor: 1196\n",
      "Diretores com apari√ß√µes registradas: 4993\n",
      "Pares √∫nicos de diretores (potenciais arestas): 1307\n",
      "\n",
      "Top 20 por grau (n√∫mero de co-diretores):\n",
      "Roger Allers: 22\n",
      "Chris Buck: 14\n",
      "Byron Howard: 13\n",
      "Peter Farrelly: 12\n",
      "Shinji Aramaki: 12\n",
      "Rusty Cundieff: 12\n",
      "Jennifer Lee: 12\n",
      "Patrick Osborne: 12\n",
      "Lauren MacMullan: 12\n",
      "John Kahrs: 12\n",
      "Nathan Greno: 12\n",
      "Stevie Wermers: 12\n",
      "Dean Wellins: 12\n",
      "Kevin Deters: 12\n",
      "Mike Gabriel: 12\n",
      "Mark Henn: 12\n",
      "Gautham Vasudev Menon: 11\n",
      "Mamoru Oshii: 11\n",
      "Hideki Futamura: 11\n",
      "Toshiyuki Kanno: 11\n",
      "\n",
      "Top 20 por apari√ß√µes:\n",
      "Rajiv Chilaka: 22\n",
      "Jan Suter: 21\n",
      "Ra√∫l Campos: 19\n",
      "Suhas Kadav: 16\n",
      "Marcus Raboy: 16\n",
      "Jay Karas: 15\n",
      "Cathy Garcia-Molina: 13\n",
      "Youssef Chahine: 12\n",
      "Martin Scorsese: 12\n",
      "Jay Chapman: 12\n",
      "Steven Spielberg: 11\n",
      "Don Michael Paul: 10\n",
      "David Dhawan: 9\n",
      "Yƒ±lmaz Erdoƒüan: 9\n",
      "Anurag Kashyap: 9\n",
      "Shannon Hartman: 9\n",
      "Quentin Tarantino: 8\n",
      "Robert Rodriguez: 8\n",
      "Hakan Alg√ºl: 8\n",
      "Hanung Bramantyo: 8\n",
      "\n",
      "‚úÖ Parse de diretores conclu√≠do.\n"
     ]
    }
   ],
   "source": [
    "# Etapa 10: Parse do CSV e constru√ß√£o das estruturas de co-diretores\n",
    "\n",
    "director_codirectors = defaultdict(set)\n",
    "pair_counts_directors = defaultdict(int)\n",
    "director_appearances = defaultdict(int)\n",
    "\n",
    "for idx, directors_cell in enumerate(df['director'].fillna('')):\n",
    "    if not directors_cell:\n",
    "        continue\n",
    "    directors = [d.strip() for d in str(directors_cell).split(',') if d.strip()]\n",
    "    for d in directors:\n",
    "        director_appearances[d] += 1\n",
    "    for d1, d2 in combinations(directors, 2):\n",
    "        key = tuple(sorted((d1, d2)))\n",
    "        pair_counts_directors[key] += 1\n",
    "        director_codirectors[d1].add(d2)\n",
    "        director_codirectors[d2].add(d1)\n",
    "\n",
    "num_directors_with_codirectors = len(director_codirectors)\n",
    "num_directors_with_appearances = len(director_appearances)\n",
    "num_pairs_directors = len(pair_counts_directors)\n",
    "\n",
    "print(f\"Total de linhas no CSV: {df.shape[0]}\")\n",
    "print(f\"Diretores com pelo menos 1 co-diretor: {num_directors_with_codirectors}\")\n",
    "print(f\"Diretores com apari√ß√µes registradas: {num_directors_with_appearances}\")\n",
    "print(f\"Pares √∫nicos de diretores (potenciais arestas): {num_pairs_directors}\")\n",
    "\n",
    "# Tops para inspe√ß√£o\n",
    "top_by_degree_dir = sorted(((director, len(neigh)) for director, neigh in director_codirectors.items()), key=lambda x: x[1], reverse=True)[:20]\n",
    "print('\\nTop 20 por grau (n√∫mero de co-diretores):')\n",
    "for director, deg in top_by_degree_dir:\n",
    "    print(f\"{director}: {deg}\")\n",
    "\n",
    "top_by_appearances_dir = sorted(director_appearances.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "print('\\nTop 20 por apari√ß√µes:')\n",
    "for director, cnt in top_by_appearances_dir:\n",
    "    print(f\"{director}: {cnt}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Parse de diretores conclu√≠do.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc24050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretores dispon√≠veis: 1196, selecionando TOP_N_DIRECTORS = 100 => selecionados: 100\n",
      "Pares no subgrafo dos TOP 100: 495\n",
      "\n",
      "Top 10 (dos selecionados) por grau:\n",
      "Roger Allers: grau=22, apari√ß√µes=3\n",
      "Chris Buck: grau=14, apari√ß√µes=3\n",
      "Byron Howard: grau=13, apari√ß√µes=2\n",
      "Peter Farrelly: grau=12, apari√ß√µes=4\n",
      "Shinji Aramaki: grau=12, apari√ß√µes=2\n",
      "Rusty Cundieff: grau=12, apari√ß√µes=2\n",
      "Jennifer Lee: grau=12, apari√ß√µes=1\n",
      "Patrick Osborne: grau=12, apari√ß√µes=1\n",
      "Lauren MacMullan: grau=12, apari√ß√µes=1\n",
      "John Kahrs: grau=12, apari√ß√µes=1\n",
      "\n",
      "‚úÖ Sele√ß√£o por grau (co-dire√ß√µes) conclu√≠da. Pr√≥ximo: construir grafo e calcular m√©tricas.\n"
     ]
    }
   ],
   "source": [
    "# Etapa 11: Selecionar TOP_N diretores por grau (co-dire√ß√µes)\n",
    "\n",
    "# Par√¢metro din√¢mico: altere antes de executar, se desejar\n",
    "TOP_N_DIRECTORS = 100\n",
    "\n",
    "# Validar que temos os dados necess√°rios\n",
    "try:\n",
    "    director_codirectors\n",
    "    pair_counts_directors\n",
    "    director_appearances\n",
    "except NameError:\n",
    "    raise FileNotFoundError('Estruturas de parsing de diretores n√£o encontradas. Execute a c√©lula de parse (Etapa 10) primeiro.')\n",
    "\n",
    "# Calcula grau (n√∫mero de co-diretores) e seleciona TOP_N\n",
    "degrees_directors = {director: len(neigh) for director, neigh in director_codirectors.items()}\n",
    "all_directors_count = len(degrees_directors)\n",
    "sorted_by_degree_dir = sorted(degrees_directors.items(), key=lambda x: x[1], reverse=True)\n",
    "top_directors = sorted_by_degree_dir[:TOP_N_DIRECTORS]\n",
    "actual_top_n_dir = len(top_directors)\n",
    "\n",
    "print(f\"Diretores dispon√≠veis: {all_directors_count}, selecionando TOP_N_DIRECTORS = {TOP_N_DIRECTORS} => selecionados: {actual_top_n_dir}\")\n",
    "\n",
    "top_names_directors = [d for d, _ in top_directors]\n",
    "top_set_directors = set(top_names_directors)\n",
    "\n",
    "# Filtrar pares onde ambos est√£o no top\n",
    "filtered_pairs_directors = {pair: cnt for pair, cnt in pair_counts_directors.items() \n",
    "                            if pair[0] in top_set_directors and pair[1] in top_set_directors}\n",
    "num_filtered_pairs_dir = len(filtered_pairs_directors)\n",
    "\n",
    "print(f\"Pares no subgrafo dos TOP {actual_top_n_dir}: {num_filtered_pairs_dir}\")\n",
    "\n",
    "# Resumo r√°pido dos 10 diretores com maior grau selecionados\n",
    "print(f'\\nTop 10 (dos selecionados) por grau:')\n",
    "for director, deg in top_directors[:10]:\n",
    "    print(f\"{director}: grau={deg}, apari√ß√µes={director_appearances.get(director, 0)}\")\n",
    "\n",
    "print(f'\\n‚úÖ Sele√ß√£o por grau (co-dire√ß√µes) conclu√≠da. Pr√≥ximo: construir grafo e calcular m√©tricas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a8dd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomes no top (por grau): 100; pares filtrados: 495\n",
      "Grafo: n√≥s=100, arestas=495\n",
      "Densidade: 0.1\n",
      "Componentes: 8; maior componente: 22 n√≥s\n",
      "\n",
      "Calculando centralidades... (isso pode levar algum tempo para betweenness se exato)\n",
      "\n",
      "M√©tricas salvas em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_diretores_codirecao/graph_metrics.csv\n",
      "\n",
      "Top 10 por Degree:\n",
      "            Director  Degree\n",
      "0       Roger Allers      21\n",
      "1         Chris Buck      12\n",
      "2       Byron Howard      12\n",
      "4     Shinji Aramaki      12\n",
      "14      Mike Gabriel      12\n",
      "6       Jennifer Lee      12\n",
      "7    Patrick Osborne      12\n",
      "8   Lauren MacMullan      12\n",
      "10      Nathan Greno      12\n",
      "9         John Kahrs      12\n",
      "\n",
      "Top 10 por Betweenness:\n",
      "            Director  Betweenness\n",
      "4     Shinji Aramaki     0.022676\n",
      "0       Roger Allers     0.022263\n",
      "38  Masaru Matsumoto     0.022263\n",
      "2       Byron Howard     0.000000\n",
      "3     Peter Farrelly     0.000000\n",
      "5     Rusty Cundieff     0.000000\n",
      "6       Jennifer Lee     0.000000\n",
      "7    Patrick Osborne     0.000000\n",
      "8   Lauren MacMullan     0.000000\n",
      "9         John Kahrs     0.000000\n",
      "\n",
      "Top 10 por Closeness:\n",
      "            Director  Closeness\n",
      "0       Roger Allers   0.212121\n",
      "1         Chris Buck   0.148485\n",
      "2       Byron Howard   0.148485\n",
      "4     Shinji Aramaki   0.148485\n",
      "14      Mike Gabriel   0.148485\n",
      "6       Jennifer Lee   0.148485\n",
      "7    Patrick Osborne   0.148485\n",
      "8   Lauren MacMullan   0.148485\n",
      "10      Nathan Greno   0.148485\n",
      "9         John Kahrs   0.148485\n",
      "\n",
      "Top 10 por PageRank:\n",
      "            Director  PageRank\n",
      "0       Roger Allers  0.017757\n",
      "4     Shinji Aramaki  0.010897\n",
      "38  Masaru Matsumoto  0.010636\n",
      "2       Byron Howard  0.010039\n",
      "14      Mike Gabriel  0.010039\n",
      "6       Jennifer Lee  0.010039\n",
      "7    Patrick Osborne  0.010039\n",
      "8   Lauren MacMullan  0.010039\n",
      "10      Nathan Greno  0.010039\n",
      "9         John Kahrs  0.010039\n",
      "\n",
      "‚úÖ Etapa 12 conclu√≠da ‚Äî m√©tricas calculadas para o grafo de co-dire√ß√£o.\n"
     ]
    }
   ],
   "source": [
    "# Etapa 12: Construir grafo NetworkX e calcular m√©tricas (Grafo de Co-Dire√ß√£o)\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir_directors = root / 'results' / 'grafo_diretores_codirecao'\n",
    "out_dir_directors.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Nomes no top (por grau): {len(top_names_directors)}; pares filtrados: {len(filtered_pairs_directors)}\")\n",
    "\n",
    "# Construir grafo ponderado (undirected)\n",
    "G_directors = nx.Graph()\n",
    "G_directors.add_nodes_from(top_names_directors)\n",
    "for (d1, d2), w in filtered_pairs_directors.items():\n",
    "    # adicionar aresta com atributo weight\n",
    "    G_directors.add_edge(d1, d2, weight=w)\n",
    "\n",
    "n_nodes_dir = G_directors.number_of_nodes()\n",
    "n_edges_dir = G_directors.number_of_edges()\n",
    "print(f\"Grafo: n√≥s={n_nodes_dir}, arestas={n_edges_dir}\")\n",
    "\n",
    "# M√©tricas globais\n",
    "density_dir = nx.density(G_directors)\n",
    "components_dir = list(nx.connected_components(G_directors))\n",
    "num_components_dir = len(components_dir)\n",
    "largest_cc_dir = max(components_dir, key=len) if components_dir else set()\n",
    "largest_cc_size_dir = len(largest_cc_dir)\n",
    "\n",
    "print(f\"Densidade: {density_dir:.6g}\")\n",
    "print(f\"Componentes: {num_components_dir}; maior componente: {largest_cc_size_dir} n√≥s\")\n",
    "\n",
    "# Centralidades\n",
    "print('\\nCalculando centralidades... (isso pode levar algum tempo para betweenness se exato)')\n",
    "# Degree centrality (normalizada)\n",
    "degree_c_dir = nx.degree_centrality(G_directors)\n",
    "# Betweenness centrality (exata ou aproximada)\n",
    "betweenness_c_dir = nx.betweenness_centrality(G_directors)\n",
    "# Closeness centrality\n",
    "closeness_c_dir = nx.closeness_centrality(G_directors)\n",
    "# PageRank (usa weights)\n",
    "pagerank_dir = nx.pagerank(G_directors, alpha=0.85, max_iter=100)\n",
    "\n",
    "# Degree raw (n√∫mero de vizinhos)\n",
    "degree_raw_dir = dict(G_directors.degree())\n",
    "\n",
    "# Montar DataFrame com m√©tricas\n",
    "metrics_df_dir = pd.DataFrame({\n",
    "    'Director': list(G_directors.nodes()),\n",
    "    'Degree': [degree_raw_dir.get(n, 0) for n in G_directors.nodes()],\n",
    "    'DegreeCentrality': [degree_c_dir.get(n, 0) for n in G_directors.nodes()],\n",
    "    'Betweenness': [betweenness_c_dir.get(n, 0) for n in G_directors.nodes()],\n",
    "    'Closeness': [closeness_c_dir.get(n, 0) for n in G_directors.nodes()],\n",
    "    'PageRank': [pagerank_dir.get(n, 0) for n in G_directors.nodes()],\n",
    "})\n",
    "\n",
    "# Normalizar colunas (opcional) ‚Äî apenas como colunas separadas para inspe√ß√£o\n",
    "metrics_df_dir['Degree_norm'] = (metrics_df_dir['Degree'] - metrics_df_dir['Degree'].min()) / (metrics_df_dir['Degree'].max() - metrics_df_dir['Degree'].min())\n",
    "metrics_df_dir['Betweenness_norm'] = (metrics_df_dir['Betweenness'] - metrics_df_dir['Betweenness'].min()) / (metrics_df_dir['Betweenness'].max() - metrics_df_dir['Betweenness'].min())\n",
    "metrics_df_dir['Closeness_norm'] = (metrics_df_dir['Closeness'] - metrics_df_dir['Closeness'].min()) / (metrics_df_dir['Closeness'].max() - metrics_df_dir['Closeness'].min())\n",
    "metrics_df_dir['PageRank_norm'] = (metrics_df_dir['PageRank'] - metrics_df_dir['PageRank'].min()) / (metrics_df_dir['PageRank'].max() - metrics_df_dir['PageRank'].min())\n",
    "\n",
    "# Salvar resultados\n",
    "metrics_csv_dir = out_dir_directors / 'graph_metrics.csv'\n",
    "metrics_df_dir.to_csv(metrics_csv_dir, index=False)\n",
    "\n",
    "# Mostrar top 10 por cada medida\n",
    "print(f\"\\nM√©tricas salvas em: {metrics_csv_dir}\")\n",
    "\n",
    "print('\\nTop 10 por Degree:')\n",
    "print(metrics_df_dir.sort_values('Degree', ascending=False).head(10)[['Director','Degree']])\n",
    "print('\\nTop 10 por Betweenness:')\n",
    "print(metrics_df_dir.sort_values('Betweenness', ascending=False).head(10)[['Director','Betweenness']])\n",
    "print('\\nTop 10 por Closeness:')\n",
    "print(metrics_df_dir.sort_values('Closeness', ascending=False).head(10)[['Director','Closeness']])\n",
    "print('\\nTop 10 por PageRank:')\n",
    "print(metrics_df_dir.sort_values('PageRank', ascending=False).head(10)[['Director','PageRank']])\n",
    "\n",
    "print('\\n‚úÖ Etapa 12 conclu√≠da ‚Äî m√©tricas calculadas para o grafo de co-dire√ß√£o.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aacd3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodando Louvain em n=22 n√≥s, m=123 arestas\n",
      "Par√¢metro de resolu√ß√£o: 1, seed: 42\n",
      "Densidade do grafo Louvain: 0.532468\n",
      "\n",
      "Modularidade obtida: 0.388\n",
      "N√∫mero de comunidades: 2\n",
      "\n",
      "Distribui√ß√£o de tamanhos (min=10, max=12, mean=11.0, median=11.0)\n",
      "\n",
      "================================================================================\n",
      "GERANDO ARQUIVOS PARA FLOURISH (DIRETORES - CO-DIRE√á√ÉO)\n",
      "================================================================================\n",
      "\n",
      "‚úÖ links.csv gerado:\n",
      "   - 123 arestas\n",
      "   - Arquivo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_diretores_codirecao/links.csv\n",
      "\n",
      "‚úÖ points.csv gerado:\n",
      "   - 22 diretores\n",
      "   - 2 comunidades\n",
      "   - Colunas: id, Community, Degree, Appearances, Betweenness, Closeness, PageRank\n",
      "   - Arquivo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_diretores_codirecao/points.csv\n",
      "\n",
      "================================================================================\n",
      "TOP 10 DIRETORES POR MEDIDA DE CENTRALIDADE (CO-DIRE√á√ÉO)\n",
      "================================================================================\n",
      "\n",
      "üîó Top 10 por Degree (n√∫mero de conex√µes):\n",
      "   15. Roger Allers: 21 conex√µes (filmes: 3)\n",
      "   1. Mike Gabriel: 12 conex√µes (filmes: 1)\n",
      "   2. Patrick Osborne: 12 conex√µes (filmes: 1)\n",
      "   3. Stevie Wermers: 12 conex√µes (filmes: 1)\n",
      "   4. Dean Wellins: 12 conex√µes (filmes: 1)\n",
      "   8. Byron Howard: 12 conex√µes (filmes: 2)\n",
      "   9. Nathan Greno: 12 conex√µes (filmes: 1)\n",
      "   12. Mark Henn: 12 conex√µes (filmes: 1)\n",
      "   13. Kevin Deters: 12 conex√µes (filmes: 1)\n",
      "   14. Lauren MacMullan: 12 conex√µes (filmes: 1)\n",
      "\n",
      "üåâ Top 10 por Betweenness (intermedia√ß√£o):\n",
      "   15. Roger Allers: 1.0000 (grau: 21, filmes: 3)\n",
      "   1. Mike Gabriel: 0.0000 (grau: 12, filmes: 1)\n",
      "   2. Patrick Osborne: 0.0000 (grau: 12, filmes: 1)\n",
      "   3. Stevie Wermers: 0.0000 (grau: 12, filmes: 1)\n",
      "   4. Dean Wellins: 0.0000 (grau: 12, filmes: 1)\n",
      "   5. Tomm Moore: 0.0000 (grau: 9, filmes: 1)\n",
      "   6. Michael Socha: 0.0000 (grau: 9, filmes: 1)\n",
      "   7. Mohammed Saeed Harib: 0.0000 (grau: 9, filmes: 1)\n",
      "   8. Byron Howard: 0.0000 (grau: 12, filmes: 2)\n",
      "   9. Nathan Greno: 0.0000 (grau: 12, filmes: 1)\n",
      "\n",
      "üìç Top 10 por Closeness (proximidade):\n",
      "   15. Roger Allers: 1.0000 (grau: 21, filmes: 3)\n",
      "   1. Mike Gabriel: 0.1750 (grau: 12, filmes: 1)\n",
      "   2. Patrick Osborne: 0.1750 (grau: 12, filmes: 1)\n",
      "   3. Stevie Wermers: 0.1750 (grau: 12, filmes: 1)\n",
      "   4. Dean Wellins: 0.1750 (grau: 12, filmes: 1)\n",
      "   8. Byron Howard: 0.1750 (grau: 12, filmes: 2)\n",
      "   9. Nathan Greno: 0.1750 (grau: 12, filmes: 1)\n",
      "   12. Mark Henn: 0.1750 (grau: 12, filmes: 1)\n",
      "   13. Kevin Deters: 0.1750 (grau: 12, filmes: 1)\n",
      "   14. Lauren MacMullan: 0.1750 (grau: 12, filmes: 1)\n",
      "\n",
      "‚≠ê Top 10 por PageRank (import√¢ncia):\n",
      "   15. Roger Allers: 1.0000 (grau: 21, filmes: 3)\n",
      "   1. Mike Gabriel: 0.1117 (grau: 12, filmes: 1)\n",
      "   2. Patrick Osborne: 0.1117 (grau: 12, filmes: 1)\n",
      "   3. Stevie Wermers: 0.1117 (grau: 12, filmes: 1)\n",
      "   4. Dean Wellins: 0.1117 (grau: 12, filmes: 1)\n",
      "   8. Byron Howard: 0.1117 (grau: 12, filmes: 2)\n",
      "   9. Nathan Greno: 0.1117 (grau: 12, filmes: 1)\n",
      "   12. Mark Henn: 0.1117 (grau: 12, filmes: 1)\n",
      "   13. Kevin Deters: 0.1117 (grau: 12, filmes: 1)\n",
      "   14. Lauren MacMullan: 0.1117 (grau: 12, filmes: 1)\n",
      "\n",
      "\n",
      " >>> Densidade do grafo de co-dire√ß√£o analisado: 0.532468 <<<\n",
      "\n",
      "================================================================================\n",
      "RESUMO DAS COMUNIDADES\n",
      "================================================================================\n",
      "\n",
      "Top 10 maiores comunidades (ID: tamanho):\n",
      "  1. Comunidade 0: 12 diretores\n",
      "  2. Comunidade 1: 10 diretores\n",
      "\n",
      "================================================================================\n",
      "ARQUIVOS FLOURISH PRONTOS!\n",
      "================================================================================\n",
      "\n",
      "üìÅ Diret√≥rio: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_diretores_codirecao\n",
      "   ‚îú‚îÄ‚îÄ links.csv    (123 arestas)\n",
      "   ‚îú‚îÄ‚îÄ points.csv   (22 n√≥s, 2 comunidades)\n",
      "   ‚îú‚îÄ‚îÄ louvain_stats.csv\n",
      "   ‚îî‚îÄ‚îÄ communities_louvain.pkl\n",
      "\n",
      "‚ú® Importe links.csv e points.csv no Flourish Network Graph!\n"
     ]
    }
   ],
   "source": [
    "# Etapa 13: Louvain + Gera√ß√£o de arquivos para Flourish (Grafo de Co-Dire√ß√£o)\n",
    "\n",
    "# Par√¢metros ajust√°veis\n",
    "LOUVAIN_RESOLUTION_DIR = 1\n",
    "USE_LARGEST_CC_DIR = True\n",
    "LOUVAIN_SEED_DIR = 42\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir_dir = root / 'results' / 'grafo_diretores_codirecao'\n",
    "out_dir_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Carregar grafo se necess√°rio\n",
    "try:\n",
    "    G_directors\n",
    "    filtered_pairs_directors\n",
    "except NameError:\n",
    "    raise FileNotFoundError('Grafo n√£o encontrado. Execute a c√©lula que constr√≥i o grafo (Etapa 12) primeiro.')\n",
    "\n",
    "# Subgrafo onde rodar Louvain\n",
    "if USE_LARGEST_CC_DIR:\n",
    "    comps_dir = list(nx.connected_components(G_directors))\n",
    "    largest_dir = max(comps_dir, key=len)\n",
    "    G_louvain_dir = G_directors.subgraph(largest_dir).copy()\n",
    "else: \n",
    "    G_louvain_dir = G_directors\n",
    "\n",
    "print(f\"Rodando Louvain em n={G_louvain_dir.number_of_nodes()} n√≥s, m={G_louvain_dir.number_of_edges()} arestas\")\n",
    "print(f\"Par√¢metro de resolu√ß√£o: {LOUVAIN_RESOLUTION_DIR}, seed: {LOUVAIN_SEED_DIR}\")\n",
    "\n",
    "# Calcular densidade do subgrafo Louvain\n",
    "density_louvain_dir = nx.density(G_louvain_dir)\n",
    "print(f\"Densidade do grafo Louvain: {density_louvain_dir:.6f}\")\n",
    "\n",
    "# Executar Louvain\n",
    "communities_sets_dir = louvain_communities(G_louvain_dir, weight='weight', resolution=LOUVAIN_RESOLUTION_DIR, seed=LOUVAIN_SEED_DIR)\n",
    "communities_list_dir = [list(c) for c in communities_sets_dir]\n",
    "\n",
    "# Calcular modularidade\n",
    "mod_dir = modularity(G_louvain_dir, communities_list_dir, weight='weight')\n",
    "num_communities_dir = len(communities_list_dir)\n",
    "\n",
    "print(f\"\\nModularidade obtida: {mod_dir:.3f}\")\n",
    "print(f\"N√∫mero de comunidades: {num_communities_dir}\")\n",
    "\n",
    "# Estat√≠sticas das comunidades\n",
    "sizes_dir = pd.Series([len(c) for c in communities_list_dir])\n",
    "print(f\"\\nDistribui√ß√£o de tamanhos (min={sizes_dir.min()}, max={sizes_dir.max()}, mean={sizes_dir.mean():.1f}, median={sizes_dir.median():.1f})\")\n",
    "\n",
    "# Criar dicion√°rio node -> community_id\n",
    "partition_dir = {}\n",
    "for cid, comm in enumerate(communities_list_dir):\n",
    "    for node in comm:\n",
    "        partition_dir[node] = cid\n",
    "\n",
    "# Estender parti√ß√£o para todos os n√≥s\n",
    "comm_dict_louvain_dir = {}\n",
    "for node in G_directors.nodes():\n",
    "    if node in partition_dir:\n",
    "        comm_dict_louvain_dir[node] = partition_dir[node]\n",
    "    else:\n",
    "        comm_dict_louvain_dir[node] = -1\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO ARQUIVOS PARA FLOURISH (DIRETORES - CO-DIRE√á√ÉO)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========== 1. GERAR links.csv ==========\n",
    "links_data_dir = []\n",
    "for (d1, d2), weight in filtered_pairs_directors.items():\n",
    "    if d1 in G_louvain_dir.nodes() and d2 in G_louvain_dir.nodes():\n",
    "        links_data_dir.append((d1, d2, weight))\n",
    "\n",
    "links_df_dir = pd.DataFrame(links_data_dir, columns=['Source', 'Target', 'Value'])\n",
    "links_csv_dir = out_dir_dir / 'links.csv'\n",
    "links_df_dir.to_csv(links_csv_dir, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ links.csv gerado:\")\n",
    "print(f\"   - {len(links_df_dir)} arestas\")\n",
    "print(f\"   - Arquivo: {links_csv_dir}\")\n",
    "\n",
    "# ========== 2. GERAR points.csv ==========\n",
    "# Calcular m√©tricas de centralidade para o subgrafo Louvain\n",
    "betweenness_louvain_dir = nx.betweenness_centrality(G_louvain_dir, weight='weight')\n",
    "closeness_louvain_dir = nx.closeness_centrality(G_louvain_dir)\n",
    "pagerank_louvain_dir = nx.pagerank(G_louvain_dir, weight='weight')\n",
    "\n",
    "# Normalizar m√©tricas (min-max normalization)\n",
    "betweenness_values_dir = list(betweenness_louvain_dir.values())\n",
    "closeness_values_dir = list(closeness_louvain_dir.values())\n",
    "pagerank_values_dir = list(pagerank_louvain_dir.values())\n",
    "\n",
    "betw_min_dir, betw_max_dir = min(betweenness_values_dir), max(betweenness_values_dir)\n",
    "clos_min_dir, clos_max_dir = min(closeness_values_dir), max(closeness_values_dir)\n",
    "pr_min_dir, pr_max_dir = min(pagerank_values_dir), max(pagerank_values_dir)\n",
    "\n",
    "points_data_dir = []\n",
    "for director in G_louvain_dir.nodes():\n",
    "    # Normalizar valores\n",
    "    betw_norm_dir = (betweenness_louvain_dir[director] - betw_min_dir) / (betw_max_dir - betw_min_dir) if betw_max_dir > betw_min_dir else 0\n",
    "    clos_norm_dir = (closeness_louvain_dir[director] - clos_min_dir) / (clos_max_dir - clos_min_dir) if clos_max_dir > clos_min_dir else 0\n",
    "    pr_norm_dir = (pagerank_louvain_dir[director] - pr_min_dir) / (pr_max_dir - pr_min_dir) if pr_max_dir > pr_min_dir else 0\n",
    "    \n",
    "    points_data_dir.append((\n",
    "        director,  # id\n",
    "        comm_dict_louvain_dir[director],  # Community\n",
    "        G_louvain_dir.degree(director),  # Degree\n",
    "        director_appearances.get(director, 0),  # Appearances\n",
    "        round(betw_norm_dir, 4),  # Betweenness (normalizado)\n",
    "        round(clos_norm_dir, 4),  # Closeness (normalizado)\n",
    "        round(pr_norm_dir, 4)  # PageRank (normalizado)\n",
    "    ))\n",
    "\n",
    "points_df_dir = pd.DataFrame(points_data_dir, columns=['id', 'Community', 'Degree', 'Appearances', 'Betweenness', 'Closeness', 'PageRank'])\n",
    "points_csv_dir = out_dir_dir / 'points.csv'\n",
    "points_df_dir.to_csv(points_csv_dir, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ points.csv gerado:\")\n",
    "print(f\"   - {len(points_df_dir)} diretores\")\n",
    "print(f\"   - {points_df_dir['Community'].nunique()} comunidades\")\n",
    "print(f\"   - Colunas: id, Community, Degree, Appearances, Betweenness, Closeness, PageRank\")\n",
    "print(f\"   - Arquivo: {points_csv_dir}\")\n",
    "\n",
    "# ========== AN√ÅLISE: TOP 10 POR CENTRALIDADE ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 DIRETORES POR MEDIDA DE CENTRALIDADE (CO-DIRE√á√ÉO)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüîó Top 10 por Degree (n√∫mero de conex√µes):\")\n",
    "for idx, row in points_df_dir.nlargest(10, 'Degree').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Degree']} conex√µes (filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\nüåâ Top 10 por Betweenness (intermedia√ß√£o):\")\n",
    "for idx, row in points_df_dir.nlargest(10, 'Betweenness').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Betweenness']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\nüìç Top 10 por Closeness (proximidade):\")\n",
    "for idx, row in points_df_dir.nlargest(10, 'Closeness').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Closeness']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\n‚≠ê Top 10 por PageRank (import√¢ncia):\")\n",
    "for idx, row in points_df_dir.nlargest(10, 'PageRank').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['PageRank']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\n\\n >>> Densidade do grafo de co-dire√ß√£o analisado: {:.6g} <<<\".format(density_louvain_dir))\n",
    "\n",
    "# ========== 3. SALVAR METADADOS ==========\n",
    "louvain_stats_dir = {\n",
    "    'resolution': LOUVAIN_RESOLUTION_DIR,\n",
    "    'seed': LOUVAIN_SEED_DIR,\n",
    "    'modularity': mod_dir,\n",
    "    'num_communities': num_communities_dir,\n",
    "    'nodes_analyzed': G_louvain_dir.number_of_nodes(),\n",
    "    'edges_analyzed': G_louvain_dir.number_of_edges()\n",
    "}\n",
    "\n",
    "pd.DataFrame([louvain_stats_dir]).to_csv(out_dir_dir / 'louvain_stats.csv', index=False)\n",
    "\n",
    "with open(out_dir_dir / 'communities_louvain.pkl', 'wb') as f:\n",
    "    pickle.dump(comm_dict_louvain_dir, f)\n",
    "\n",
    "# ========== 4. RESUMO DAS COMUNIDADES ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO DAS COMUNIDADES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comm_sizes_dir = points_df_dir['Community'].value_counts().sort_values(ascending=False)\n",
    "print(f\"\\nTop 10 maiores comunidades (ID: tamanho):\")\n",
    "for idx, (comm_id, size) in enumerate(comm_sizes_dir.head(10).items(), 1):\n",
    "    print(f\"  {idx}. Comunidade {comm_id}: {size} diretores\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARQUIVOS FLOURISH PRONTOS!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÅ Diret√≥rio: {out_dir_dir}\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ links.csv    ({len(links_df_dir)} arestas)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ points.csv   ({len(points_df_dir)} n√≥s, {num_communities_dir} comunidades)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ louvain_stats.csv\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ communities_louvain.pkl\")\n",
    "print(\"\\n‚ú® Importe links.csv e points.csv no Flourish Network Graph!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7b585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Top 100 diretores por n√∫mero de filmes:\n",
      "   - Diretor com mais filmes: Rajiv Chilaka (22 filmes)\n",
      "   - Diretor na posi√ß√£o 100: Mahesh Manjrekar (5 filmes)\n",
      "\n",
      "üìä Arestas ap√≥s filtro:\n",
      "   - Total de arestas (co-dire√ß√µes): 9\n",
      "\n",
      "üîó Distribui√ß√£o de grau (conex√µes):\n",
      "   - M√©dia: 1.80\n",
      "   - Mediana: 1.0\n",
      "   - M√°ximo: 3\n",
      "   - M√≠nimo: 1\n"
     ]
    }
   ],
   "source": [
    "# Etapa 14: Selecionar top diretores por apari√ß√µes (filmes)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "TOP_N_DIRECTORS_APPEARANCES = 100\n",
    "\n",
    "# Ordenar diretores por n√∫mero de apari√ß√µes\n",
    "director_ranking_appearances = sorted(director_appearances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Pegar top N\n",
    "top_directors_appearances = director_ranking_appearances[:TOP_N_DIRECTORS_APPEARANCES]\n",
    "top_names_directors_appearances = {director for director, _ in top_directors_appearances}\n",
    "\n",
    "print(f\"\\nüé¨ Top {TOP_N_DIRECTORS_APPEARANCES} diretores por n√∫mero de filmes:\")\n",
    "print(f\"   - Diretor com mais filmes: {top_directors_appearances[0][0]} ({top_directors_appearances[0][1]} filmes)\")\n",
    "print(f\"   - Diretor na posi√ß√£o {TOP_N_DIRECTORS_APPEARANCES}: {top_directors_appearances[-1][0]} ({top_directors_appearances[-1][1]} filmes)\")\n",
    "\n",
    "# Filtrar pares de co-dire√ß√£o para incluir apenas top diretores\n",
    "filtered_pairs_directors_appearances = {}\n",
    "for (d1, d2), weight in pair_counts_directors.items():\n",
    "    if d1 in top_names_directors_appearances and d2 in top_names_directors_appearances:\n",
    "        filtered_pairs_directors_appearances[(d1, d2)] = weight\n",
    "\n",
    "print(f\"\\nüìä Arestas ap√≥s filtro:\")\n",
    "print(f\"   - Total de arestas (co-dire√ß√µes): {len(filtered_pairs_directors_appearances)}\")\n",
    "\n",
    "# Calcular grau para os top diretores\n",
    "director_degrees_appearances = Counter()\n",
    "for (d1, d2) in filtered_pairs_directors_appearances.keys():\n",
    "    director_degrees_appearances[d1] += 1\n",
    "    director_degrees_appearances[d2] += 1\n",
    "\n",
    "print(f\"\\nüîó Distribui√ß√£o de grau (conex√µes):\")\n",
    "degrees_series_app = pd.Series(list(director_degrees_appearances.values()))\n",
    "print(f\"   - M√©dia: {degrees_series_app.mean():.2f}\")\n",
    "print(f\"   - Mediana: {degrees_series_app.median():.1f}\")\n",
    "print(f\"   - M√°ximo: {degrees_series_app.max()}\")\n",
    "print(f\"   - M√≠nimo: {degrees_series_app.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a2e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä GRAFO CONSTRU√çDO (Diretores com Mais Filmes)\n",
      "   - N√≥s: 10\n",
      "   - Arestas: 9\n",
      "   - Densidade: 0.2000\n",
      "\n",
      "üîó Componentes Conexas:\n",
      "   - Total: 4\n",
      "   - Maior componente: 4 n√≥s (40.0%)\n",
      "\n",
      "‚è≥ Calculando m√©tricas de centralidade...\n",
      "‚úÖ M√©tricas calculadas!\n",
      "\n",
      "üíæ M√©tricas salvas em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_diretores_mais_filmes/graph_metrics.csv\n",
      "\n",
      "üèÜ Top 10 diretores por PageRank:\n",
      "   1. Alex Woo: 0.1000 (filmes: 5, grau: 1)\n",
      "   2. Stanley Moore: 0.1000 (filmes: 5, grau: 1)\n",
      "   3. Priyadarshan: 0.1000 (filmes: 7, grau: 1)\n",
      "   4. Rathindran R Prasad: 0.1000 (filmes: 5, grau: 1)\n",
      "   5. Anurag Kashyap: 0.1000 (filmes: 9, grau: 3)\n",
      "   6. Dibakar Banerjee: 0.1000 (filmes: 7, grau: 3)\n",
      "   7. Karan Johar: 0.1000 (filmes: 6, grau: 3)\n",
      "   8. Zoya Akhtar: 0.1000 (filmes: 6, grau: 3)\n",
      "   9. Jan Suter: 0.1000 (filmes: 21, grau: 1)\n",
      "   10. Ra√∫l Campos: 0.1000 (filmes: 19, grau: 1)\n"
     ]
    }
   ],
   "source": [
    "# Etapa 15: Construir grafo NetworkX e calcular m√©tricas (Diretores com Mais Filmes)\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir_app_directors = root / 'results' / 'grafo_diretores_mais_filmes'\n",
    "out_dir_app_directors.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Criar grafo\n",
    "G_directors_appearances = nx.Graph()\n",
    "\n",
    "# Adicionar arestas com peso\n",
    "for (d1, d2), weight in filtered_pairs_directors_appearances.items():\n",
    "    G_directors_appearances.add_edge(d1, d2, weight=weight)\n",
    "\n",
    "# Adicionar atributo de apari√ß√µes aos n√≥s\n",
    "for director in G_directors_appearances.nodes():\n",
    "    G_directors_appearances.nodes[director]['appearances'] = director_appearances.get(director, 0)\n",
    "\n",
    "print(f\"\\nüìä GRAFO CONSTRU√çDO (Diretores com Mais Filmes)\")\n",
    "print(f\"   - N√≥s: {G_directors_appearances.number_of_nodes()}\")\n",
    "print(f\"   - Arestas: {G_directors_appearances.number_of_edges()}\")\n",
    "print(f\"   - Densidade: {nx.density(G_directors_appearances):.4f}\")\n",
    "\n",
    "# Componentes conexas\n",
    "num_cc_app_dir = nx.number_connected_components(G_directors_appearances)\n",
    "cc_sizes_app_dir = [len(c) for c in nx.connected_components(G_directors_appearances)]\n",
    "\n",
    "print(f\"\\nüîó Componentes Conexas:\")\n",
    "print(f\"   - Total: {num_cc_app_dir}\")\n",
    "print(f\"   - Maior componente: {max(cc_sizes_app_dir)} n√≥s ({max(cc_sizes_app_dir)/G_directors_appearances.number_of_nodes()*100:.1f}%)\")\n",
    "\n",
    "# Calcular m√©tricas de centralidade\n",
    "print(\"\\n‚è≥ Calculando m√©tricas de centralidade...\")\n",
    "\n",
    "degree_centrality_app_dir = nx.degree_centrality(G_directors_appearances)\n",
    "betweenness_centrality_app_dir = nx.betweenness_centrality(G_directors_appearances, weight='weight')\n",
    "closeness_centrality_app_dir = nx.closeness_centrality(G_directors_appearances)\n",
    "pagerank_app_dir = nx.pagerank(G_directors_appearances, weight='weight')\n",
    "\n",
    "print(\"‚úÖ M√©tricas calculadas!\")\n",
    "\n",
    "# Criar DataFrame com todas as m√©tricas\n",
    "metrics_data_app_dir = []\n",
    "for director in G_directors_appearances.nodes():\n",
    "    metrics_data_app_dir.append({\n",
    "        'director': director,\n",
    "        'degree': G_directors_appearances.degree(director),\n",
    "        'degree_centrality': degree_centrality_app_dir[director],\n",
    "        'betweenness_centrality': betweenness_centrality_app_dir[director],\n",
    "        'closeness_centrality': closeness_centrality_app_dir[director],\n",
    "        'pagerank': pagerank_app_dir[director],\n",
    "        'appearances': director_appearances.get(director, 0)\n",
    "    })\n",
    "\n",
    "metrics_df_app_dir = pd.DataFrame(metrics_data_app_dir)\n",
    "\n",
    "# Ordenar por PageRank\n",
    "metrics_df_app_dir = metrics_df_app_dir.sort_values('pagerank', ascending=False)\n",
    "\n",
    "# Salvar m√©tricas\n",
    "metrics_csv_app_dir = out_dir_app_directors / 'graph_metrics.csv'\n",
    "metrics_df_app_dir.to_csv(metrics_csv_app_dir, index=False)\n",
    "\n",
    "print(f\"\\nüíæ M√©tricas salvas em: {metrics_csv_app_dir}\")\n",
    "\n",
    "# Exibir top 10 por PageRank\n",
    "print(f\"\\nüèÜ Top 10 diretores por PageRank:\")\n",
    "for idx, row in metrics_df_app_dir.head(10).iterrows():\n",
    "    print(f\"   {row.name+1}. {row['director']}: {row['pagerank']:.4f} (filmes: {int(row['appearances'])}, grau: {int(row['degree'])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec75cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodando Louvain em n=4 n√≥s, m=6 arestas\n",
      "Par√¢metro de resolu√ß√£o: 1, seed: 42\n",
      "Densidade do grafo Louvain: 1.000000\n",
      "\n",
      "Modularidade obtida: 0.000\n",
      "N√∫mero de comunidades: 1\n",
      "\n",
      "Distribui√ß√£o de tamanhos (min=4, max=4, mean=4.0, median=4.0)\n",
      "\n",
      "================================================================================\n",
      "GERANDO ARQUIVOS PARA FLOURISH (DIRETORES - MAIS FILMES)\n",
      "================================================================================\n",
      "\n",
      "‚úÖ links.csv gerado:\n",
      "   - 6 arestas\n",
      "   - Arquivo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_diretores_mais_filmes/links.csv\n",
      "\n",
      "‚úÖ points.csv gerado:\n",
      "   - 4 diretores\n",
      "   - 1 comunidades\n",
      "   - Colunas: id, Community, Degree, Appearances, Betweenness, Closeness, PageRank\n",
      "   - Arquivo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_diretores_mais_filmes/points.csv\n",
      "\n",
      "================================================================================\n",
      "TOP 10 DIRETORES POR MEDIDA DE CENTRALIDADE (MAIS FILMES)\n",
      "================================================================================\n",
      "\n",
      "üîó Top 10 por Degree (n√∫mero de conex√µes):\n",
      "   1. Karan Johar: 3 conex√µes (filmes: 6)\n",
      "   2. Dibakar Banerjee: 3 conex√µes (filmes: 7)\n",
      "   3. Zoya Akhtar: 3 conex√µes (filmes: 6)\n",
      "   4. Anurag Kashyap: 3 conex√µes (filmes: 9)\n",
      "\n",
      "üåâ Top 10 por Betweenness (intermedia√ß√£o):\n",
      "   1. Karan Johar: 0.0000 (grau: 3, filmes: 6)\n",
      "   2. Dibakar Banerjee: 0.0000 (grau: 3, filmes: 7)\n",
      "   3. Zoya Akhtar: 0.0000 (grau: 3, filmes: 6)\n",
      "   4. Anurag Kashyap: 0.0000 (grau: 3, filmes: 9)\n",
      "\n",
      "üìç Top 10 por Closeness (proximidade):\n",
      "   1. Karan Johar: 0.0000 (grau: 3, filmes: 6)\n",
      "   2. Dibakar Banerjee: 0.0000 (grau: 3, filmes: 7)\n",
      "   3. Zoya Akhtar: 0.0000 (grau: 3, filmes: 6)\n",
      "   4. Anurag Kashyap: 0.0000 (grau: 3, filmes: 9)\n",
      "\n",
      "‚≠ê Top 10 por PageRank (import√¢ncia):\n",
      "   1. Karan Johar: 0.0000 (grau: 3, filmes: 6)\n",
      "   2. Dibakar Banerjee: 0.0000 (grau: 3, filmes: 7)\n",
      "   3. Zoya Akhtar: 0.0000 (grau: 3, filmes: 6)\n",
      "   4. Anurag Kashyap: 0.0000 (grau: 3, filmes: 9)\n",
      "\n",
      "\n",
      " >>> Densidade do grafo de diretores com mais filmes analisado: 1 <<<\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISE DETALHADA DAS COMUNIDADES\n",
      "================================================================================\n",
      "\n",
      "‚úÖ An√°lise de comunidades salva em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_diretores_mais_filmes/community_analysis.csv\n",
      "\n",
      "üèÜ Top 5 maiores comunidades:\n",
      "\n",
      "   Comunidade 0:\n",
      "   - Tamanho: 4 diretores\n",
      "   - Total de filmes: 28\n",
      "   - M√©dia de filmes: 7.0\n",
      "   - Diretor mais produtivo: Anurag Kashyap (9 filmes)\n",
      "\n",
      "================================================================================\n",
      "ARQUIVOS FLOURISH PRONTOS!\n",
      "================================================================================\n",
      "\n",
      "üìÅ Diret√≥rio: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_diretores_mais_filmes\n",
      "   ‚îú‚îÄ‚îÄ links.csv              (6 arestas)\n",
      "   ‚îú‚îÄ‚îÄ points.csv             (4 n√≥s, 1 comunidades)\n",
      "   ‚îú‚îÄ‚îÄ community_analysis.csv (1 comunidades)\n",
      "   ‚îú‚îÄ‚îÄ louvain_stats.csv\n",
      "   ‚îî‚îÄ‚îÄ communities_louvain.pkl\n",
      "\n",
      "‚ú® Importe links.csv e points.csv no Flourish Network Graph!\n"
     ]
    }
   ],
   "source": [
    "# Etapa 16: Louvain + Gera√ß√£o de arquivos para Flourish + An√°lise de Comunidades (Diretores com Mais Filmes)\n",
    "\n",
    "# Par√¢metros ajust√°veis\n",
    "LOUVAIN_RESOLUTION_DIR_APP = 1\n",
    "USE_LARGEST_CC_DIR_APP = True\n",
    "LOUVAIN_SEED_DIR_APP = 42\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir_dir_app = root / 'results' / 'grafo_diretores_mais_filmes'\n",
    "out_dir_dir_app.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Carregar grafo se necess√°rio\n",
    "try:\n",
    "    G_directors_appearances\n",
    "    filtered_pairs_directors_appearances\n",
    "except NameError:\n",
    "    raise FileNotFoundError('Grafo n√£o encontrado. Execute a c√©lula que constr√≥i o grafo (Etapa 15) primeiro.')\n",
    "\n",
    "# Subgrafo onde rodar Louvain\n",
    "if USE_LARGEST_CC_DIR_APP:\n",
    "    comps_dir_app = list(nx.connected_components(G_directors_appearances))\n",
    "    largest_dir_app = max(comps_dir_app, key=len)\n",
    "    G_louvain_dir_app = G_directors_appearances.subgraph(largest_dir_app).copy()\n",
    "else:\n",
    "    G_louvain_dir_app = G_directors_appearances\n",
    "\n",
    "print(f\"Rodando Louvain em n={G_louvain_dir_app.number_of_nodes()} n√≥s, m={G_louvain_dir_app.number_of_edges()} arestas\")\n",
    "print(f\"Par√¢metro de resolu√ß√£o: {LOUVAIN_RESOLUTION_DIR_APP}, seed: {LOUVAIN_SEED_DIR_APP}\")\n",
    "\n",
    "# Calcular densidade do subgrafo Louvain\n",
    "density_louvain_dir_app = nx.density(G_louvain_dir_app)\n",
    "print(f\"Densidade do grafo Louvain: {density_louvain_dir_app:.6f}\")\n",
    "\n",
    "# Executar Louvain\n",
    "communities_sets_dir_app = louvain_communities(G_louvain_dir_app, weight='weight', resolution=LOUVAIN_RESOLUTION_DIR_APP, seed=LOUVAIN_SEED_DIR_APP)\n",
    "communities_list_dir_app = [list(c) for c in communities_sets_dir_app]\n",
    "\n",
    "# Calcular modularidade\n",
    "mod_dir_app = modularity(G_louvain_dir_app, communities_list_dir_app, weight='weight')\n",
    "num_communities_dir_app = len(communities_list_dir_app)\n",
    "\n",
    "print(f\"\\nModularidade obtida: {mod_dir_app:.3f}\")\n",
    "print(f\"N√∫mero de comunidades: {num_communities_dir_app}\")\n",
    "\n",
    "# Estat√≠sticas das comunidades\n",
    "sizes_dir_app = pd.Series([len(c) for c in communities_list_dir_app])\n",
    "print(f\"\\nDistribui√ß√£o de tamanhos (min={sizes_dir_app.min()}, max={sizes_dir_app.max()}, mean={sizes_dir_app.mean():.1f}, median={sizes_dir_app.median():.1f})\")\n",
    "\n",
    "# Criar dicion√°rio node -> community_id\n",
    "partition_dir_app = {}\n",
    "for cid, comm in enumerate(communities_list_dir_app):\n",
    "    for node in comm:\n",
    "        partition_dir_app[node] = cid\n",
    "\n",
    "# Estender parti√ß√£o para todos os n√≥s\n",
    "comm_dict_louvain_dir_app = {}\n",
    "for node in G_directors_appearances.nodes():\n",
    "    if node in partition_dir_app:\n",
    "        comm_dict_louvain_dir_app[node] = partition_dir_app[node]\n",
    "    else:\n",
    "        comm_dict_louvain_dir_app[node] = -1\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO ARQUIVOS PARA FLOURISH (DIRETORES - MAIS FILMES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========== 1. GERAR links.csv ==========\n",
    "links_data_dir_app = []\n",
    "for (d1, d2), weight in filtered_pairs_directors_appearances.items():\n",
    "    if d1 in G_louvain_dir_app.nodes() and d2 in G_louvain_dir_app.nodes():\n",
    "        links_data_dir_app.append((d1, d2, weight))\n",
    "\n",
    "links_df_dir_app = pd.DataFrame(links_data_dir_app, columns=['Source', 'Target', 'Value'])\n",
    "links_csv_dir_app = out_dir_dir_app / 'links.csv'\n",
    "links_df_dir_app.to_csv(links_csv_dir_app, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ links.csv gerado:\")\n",
    "print(f\"   - {len(links_df_dir_app)} arestas\")\n",
    "print(f\"   - Arquivo: {links_csv_dir_app}\")\n",
    "\n",
    "# ========== 2. GERAR points.csv ==========\n",
    "# Calcular m√©tricas de centralidade para o subgrafo Louvain\n",
    "betweenness_louvain_dir_app = nx.betweenness_centrality(G_louvain_dir_app, weight='weight')\n",
    "closeness_louvain_dir_app = nx.closeness_centrality(G_louvain_dir_app)\n",
    "pagerank_louvain_dir_app = nx.pagerank(G_louvain_dir_app, weight='weight')\n",
    "\n",
    "# Normalizar m√©tricas (min-max normalization)\n",
    "betweenness_values_dir_app = list(betweenness_louvain_dir_app.values())\n",
    "closeness_values_dir_app = list(closeness_louvain_dir_app.values())\n",
    "pagerank_values_dir_app = list(pagerank_louvain_dir_app.values())\n",
    "\n",
    "betw_min_dir_app, betw_max_dir_app = min(betweenness_values_dir_app), max(betweenness_values_dir_app)\n",
    "clos_min_dir_app, clos_max_dir_app = min(closeness_values_dir_app), max(closeness_values_dir_app)\n",
    "pr_min_dir_app, pr_max_dir_app = min(pagerank_values_dir_app), max(pagerank_values_dir_app)\n",
    "\n",
    "points_data_dir_app = []\n",
    "for director in G_louvain_dir_app.nodes():\n",
    "    # Normalizar valores\n",
    "    betw_norm_dir_app = (betweenness_louvain_dir_app[director] - betw_min_dir_app) / (betw_max_dir_app - betw_min_dir_app) if betw_max_dir_app > betw_min_dir_app else 0\n",
    "    clos_norm_dir_app = (closeness_louvain_dir_app[director] - clos_min_dir_app) / (clos_max_dir_app - clos_min_dir_app) if clos_max_dir_app > clos_min_dir_app else 0\n",
    "    pr_norm_dir_app = (pagerank_louvain_dir_app[director] - pr_min_dir_app) / (pr_max_dir_app - pr_min_dir_app) if pr_max_dir_app > pr_min_dir_app else 0\n",
    "    \n",
    "    points_data_dir_app.append((\n",
    "        director,  # id\n",
    "        comm_dict_louvain_dir_app[director],  # Community\n",
    "        G_louvain_dir_app.degree(director),  # Degree\n",
    "        director_appearances.get(director, 0),  # Appearances\n",
    "        round(betw_norm_dir_app, 4),  # Betweenness (normalizado)\n",
    "        round(clos_norm_dir_app, 4),  # Closeness (normalizado)\n",
    "        round(pr_norm_dir_app, 4)  # PageRank (normalizado)\n",
    "    ))\n",
    "\n",
    "points_df_dir_app = pd.DataFrame(points_data_dir_app, columns=['id', 'Community', 'Degree', 'Appearances', 'Betweenness', 'Closeness', 'PageRank'])\n",
    "points_csv_dir_app = out_dir_dir_app / 'points.csv'\n",
    "points_df_dir_app.to_csv(points_csv_dir_app, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ points.csv gerado:\")\n",
    "print(f\"   - {len(points_df_dir_app)} diretores\")\n",
    "print(f\"   - {points_df_dir_app['Community'].nunique()} comunidades\")\n",
    "print(f\"   - Colunas: id, Community, Degree, Appearances, Betweenness, Closeness, PageRank\")\n",
    "print(f\"   - Arquivo: {points_csv_dir_app}\")\n",
    "\n",
    "# ========== AN√ÅLISE: TOP 10 POR CENTRALIDADE ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 DIRETORES POR MEDIDA DE CENTRALIDADE (MAIS FILMES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüîó Top 10 por Degree (n√∫mero de conex√µes):\")\n",
    "for idx, row in points_df_dir_app.nlargest(10, 'Degree').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Degree']} conex√µes (filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\nüåâ Top 10 por Betweenness (intermedia√ß√£o):\")\n",
    "for idx, row in points_df_dir_app.nlargest(10, 'Betweenness').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Betweenness']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\nüìç Top 10 por Closeness (proximidade):\")\n",
    "for idx, row in points_df_dir_app.nlargest(10, 'Closeness').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['Closeness']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\n‚≠ê Top 10 por PageRank (import√¢ncia):\")\n",
    "for idx, row in points_df_dir_app.nlargest(10, 'PageRank').iterrows():\n",
    "    print(f\"   {idx+1}. {row['id']}: {row['PageRank']:.4f} (grau: {row['Degree']}, filmes: {row['Appearances']})\")\n",
    "\n",
    "print(\"\\n\\n >>> Densidade do grafo de diretores com mais filmes analisado: {:.6g} <<<\".format(density_louvain_dir_app))\n",
    "\n",
    "# ========== 3. SALVAR METADADOS ==========\n",
    "louvain_stats_dir_app = {\n",
    "    'resolution': LOUVAIN_RESOLUTION_DIR_APP,\n",
    "    'seed': LOUVAIN_SEED_DIR_APP,\n",
    "    'modularity': mod_dir_app,\n",
    "    'num_communities': num_communities_dir_app,\n",
    "    'nodes_analyzed': G_louvain_dir_app.number_of_nodes(),\n",
    "    'edges_analyzed': G_louvain_dir_app.number_of_edges()\n",
    "}\n",
    "\n",
    "pd.DataFrame([louvain_stats_dir_app]).to_csv(out_dir_dir_app / 'louvain_stats.csv', index=False)\n",
    "\n",
    "with open(out_dir_dir_app / 'communities_louvain.pkl', 'wb') as f:\n",
    "    pickle.dump(comm_dict_louvain_dir_app, f)\n",
    "\n",
    "# ========== 4. AN√ÅLISE DETALHADA DAS COMUNIDADES ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISE DETALHADA DAS COMUNIDADES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "community_analysis_dir_app = []\n",
    "for comm_id, members in enumerate(communities_list_dir_app):\n",
    "    # Filtrar apenas diretores nesta comunidade\n",
    "    comm_df = points_df_dir_app[points_df_dir_app['Community'] == comm_id]\n",
    "    \n",
    "    # Calcular estat√≠sticas\n",
    "    total_appearances = comm_df['Appearances'].sum()\n",
    "    avg_appearances = comm_df['Appearances'].mean()\n",
    "    max_appearances = comm_df['Appearances'].max()\n",
    "    \n",
    "    # Diretor com mais filmes na comunidade\n",
    "    top_director = comm_df.loc[comm_df['Appearances'].idxmax(), 'id']\n",
    "    \n",
    "    community_analysis_dir_app.append({\n",
    "        'community_id': comm_id,\n",
    "        'size': len(members),\n",
    "        'total_appearances': total_appearances,\n",
    "        'avg_appearances': avg_appearances,\n",
    "        'max_appearances': max_appearances,\n",
    "        'top_director': top_director\n",
    "    })\n",
    "\n",
    "community_df_dir_app = pd.DataFrame(community_analysis_dir_app)\n",
    "community_df_dir_app = community_df_dir_app.sort_values('size', ascending=False)\n",
    "\n",
    "# Salvar an√°lise\n",
    "community_csv_dir_app = out_dir_dir_app / 'community_analysis.csv'\n",
    "community_df_dir_app.to_csv(community_csv_dir_app, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lise de comunidades salva em: {community_csv_dir_app}\")\n",
    "\n",
    "# Exibir top 5 comunidades\n",
    "print(f\"\\nüèÜ Top 5 maiores comunidades:\")\n",
    "for idx, row in community_df_dir_app.head(5).iterrows():\n",
    "    print(f\"\\n   Comunidade {int(row['community_id'])}:\")\n",
    "    print(f\"   - Tamanho: {int(row['size'])} diretores\")\n",
    "    print(f\"   - Total de filmes: {int(row['total_appearances'])}\")\n",
    "    print(f\"   - M√©dia de filmes: {row['avg_appearances']:.1f}\")\n",
    "    print(f\"   - Diretor mais produtivo: {row['top_director']} ({int(row['max_appearances'])} filmes)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARQUIVOS FLOURISH PRONTOS!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÅ Diret√≥rio: {out_dir_dir_app}\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ links.csv              ({len(links_df_dir_app)} arestas)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ points.csv             ({len(points_df_dir_app)} n√≥s, {num_communities_dir_app} comunidades)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ community_analysis.csv ({num_communities_dir_app} comunidades)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ louvain_stats.csv\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ communities_louvain.pkl\")\n",
    "print(\"\\n‚ú® Importe links.csv e points.csv no Flourish Network Graph!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt108_projeto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
