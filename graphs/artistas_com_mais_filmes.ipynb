{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d784b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import time\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5aaf267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7f01920a1450>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configura√ß√£o do backend do matplotlib para notebooks\n",
    "import os\n",
    "# Remove a vari√°vel de ambiente que causa conflito\n",
    "if 'MPLBACKEND' in os.environ:\n",
    "    del os.environ['MPLBACKEND']\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Backend n√£o-interativo que funciona em qualquer ambiente\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Para garantir que os gr√°ficos sejam exibidos no notebook\n",
    "plt.ion()  # Ativa modo interativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67a834",
   "metadata": {},
   "source": [
    "# Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f61bc40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/datasets/netflix_titles.csv\n"
     ]
    }
   ],
   "source": [
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "# garante que encontramos o dataset independentemente do cwd do notebook\n",
    "input_file = root / 'datasets' / 'netflix_titles.csv'\n",
    "\n",
    "print(f\"Lendo: {input_file}\")\n",
    "\n",
    "df = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab55fb",
   "metadata": {},
   "source": [
    "## An√°lise geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "306758f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas no CSV: 8807\n",
      "Atores com pelo menos 1 co-ator: 36039\n",
      "Atores com apari√ß√µes registradas: 36439\n",
      "Pares √∫nicos de atores (potenciais arestas): 289207\n",
      "\n",
      "Top 20 por grau (n√∫mero de coatores):\n",
      "Anupam Kher: 273\n",
      "Samuel L. Jackson: 239\n",
      "Takahiro Sakurai: 228\n",
      "Fred Tatasciore: 226\n",
      "Yuichi Nakamura: 223\n",
      "Yuki Kaji: 220\n",
      "Shah Rukh Khan: 210\n",
      "Fred Armisen: 209\n",
      "Akshay Kumar: 193\n",
      "Katsuyuki Konishi: 191\n",
      "Jun Fukuyama: 188\n",
      "Om Puri: 187\n",
      "Junichi Suwabe: 185\n",
      "Naseeruddin Shah: 183\n",
      "Boman Irani: 183\n",
      "Hiroshi Kamiya: 182\n",
      "James Franco: 182\n",
      "Maya Rudolph: 181\n",
      "Paresh Rawal: 179\n",
      "Amitabh Bachchan: 178\n",
      "\n",
      "Top 20 por apari√ß√µes:\n",
      "Anupam Kher: 43\n",
      "Shah Rukh Khan: 35\n",
      "Julie Tejwani: 33\n",
      "Naseeruddin Shah: 32\n",
      "Takahiro Sakurai: 32\n",
      "Rupa Bhimani: 31\n",
      "Akshay Kumar: 30\n",
      "Om Puri: 30\n",
      "Yuki Kaji: 29\n",
      "Amitabh Bachchan: 28\n",
      "Paresh Rawal: 28\n",
      "Boman Irani: 27\n",
      "Rajesh Kava: 26\n",
      "Vincent Tong: 26\n",
      "Andrea Libman: 25\n",
      "Kareena Kapoor: 25\n",
      "Samuel L. Jackson: 24\n",
      "John Cleese: 24\n",
      "Jigna Bhardwaj: 23\n",
      "Fred Tatasciore: 23\n",
      "\n",
      "Arquivos intermedi√°rios salvos em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2: Parse do CSV e constru√ß√£o das estruturas de co-atores\n",
    "\n",
    "actor_coactors = defaultdict(set)\n",
    "pair_counts = defaultdict(int)\n",
    "actor_appearances = defaultdict(int)\n",
    "\n",
    "for idx, cast in enumerate(df['cast'].fillna('')):\n",
    "    if not cast:\n",
    "        continue\n",
    "    actors = [a.strip() for a in cast.split(',') if a.strip()]\n",
    "    for a in actors:\n",
    "        actor_appearances[a] += 1\n",
    "    for a, b in combinations(actors, 2):\n",
    "        key = tuple(sorted((a, b)))\n",
    "        pair_counts[key] += 1\n",
    "        actor_coactors[a].add(b)\n",
    "        actor_coactors[b].add(a)\n",
    "\n",
    "num_actors_with_coactors = len(actor_coactors)\n",
    "num_actors_with_appearances = len(actor_appearances)\n",
    "num_pairs = len(pair_counts)\n",
    "\n",
    "print(f\"Total de linhas no CSV: {df.shape[0]}\")\n",
    "print(f\"Atores com pelo menos 1 co-ator: {num_actors_with_coactors}\")\n",
    "print(f\"Atores com apari√ß√µes registradas: {num_actors_with_appearances}\")\n",
    "print(f\"Pares √∫nicos de atores (potenciais arestas): {num_pairs}\")\n",
    "\n",
    "# Tops para inspe√ß√£o\n",
    "top_by_degree = sorted(((actor, len(neigh)) for actor, neigh in actor_coactors.items()), key=lambda x: x[1], reverse=True)[:20]\n",
    "print('\\nTop 20 por grau (n√∫mero de coatores):')\n",
    "for actor, deg in top_by_degree:\n",
    "    print(f\"{actor}: {deg}\")\n",
    "\n",
    "top_by_appearances = sorted(actor_appearances.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "print('\\nTop 20 por apari√ß√µes:')\n",
    "for actor, cnt in top_by_appearances:\n",
    "    print(f\"{actor}: {cnt}\")\n",
    "\n",
    "# Salvando intermedi√°rios em results/q1\n",
    "out_dir = root / 'results'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Salvar tops em CSVs para inspe√ß√£o\n",
    "pd.DataFrame(top_by_appearances, columns=['Actor', 'Appearances']).to_csv(out_dir / 'top_by_appearances.csv', index=False)\n",
    "pd.DataFrame(top_by_degree, columns=['Actor', 'Degree']).to_csv(out_dir / 'top_by_degree.csv', index=False)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nArquivos intermedi√°rios salvos em: {out_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07cd31b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atores dispon√≠veis: 36039, selecionando TOP_N = 100 => selecionados: 100\n",
      "Pares no subgrafo dos TOP 100: 583\n",
      "Arquivos gerados (n√£o para Flourish ainda):\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/links_top.csv\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/top_actors.csv\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/filtered_pair_counts.pkl\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/top_actor_names.pkl\n",
      "\n",
      "Top 10 (dos selecionados) por grau:\n",
      "Anupam Kher: grau=273, apari√ß√µes=43\n",
      "Samuel L. Jackson: grau=239, apari√ß√µes=24\n",
      "Takahiro Sakurai: grau=228, apari√ß√µes=32\n",
      "Fred Tatasciore: grau=226, apari√ß√µes=23\n",
      "Yuichi Nakamura: grau=223, apari√ß√µes=19\n",
      "Yuki Kaji: grau=220, apari√ß√µes=29\n",
      "Shah Rukh Khan: grau=210, apari√ß√µes=35\n",
      "Fred Armisen: grau=209, apari√ß√µes=19\n",
      "Akshay Kumar: grau=193, apari√ß√µes=30\n",
      "Katsuyuki Konishi: grau=191, apari√ß√µes=12\n"
     ]
    }
   ],
   "source": [
    "# Etapa 3 (separada): Selecionar TOP_N atores por grau (conex√µes)\n",
    "# N√£o executo esta c√©lula automaticamente ‚Äî confirme quando quiser rodar.\n",
    "\n",
    "# Par√¢metro din√¢mico: altere antes de executar, se desejar\n",
    "TOP_N = 100\n",
    "\n",
    "# Determina paths conforme o notebook\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir = root / 'results' / 'q1'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Tenta usar vari√°veis em mem√≥ria (caso a c√©lula de parsing tenha sido executada);\n",
    "# caso contr√°rio, carrega os pickles gerados pela etapa de parsing.\n",
    "try:\n",
    "    actor_coactors\n",
    "    pair_counts\n",
    "    actor_appearances\n",
    "except NameError:\n",
    "    # tenta carregar arquivos em results/q1\n",
    "    try:\n",
    "        with open(out_dir / 'actor_coactors.pkl', 'rb') as f:\n",
    "            actor_coactors = pickle.load(f)\n",
    "        with open(out_dir / 'pair_counts.pkl', 'rb') as f:\n",
    "            pair_counts = pickle.load(f)\n",
    "        with open(out_dir / 'actor_appearances.pkl', 'rb') as f:\n",
    "            actor_appearances = pickle.load(f)\n",
    "        print('Carreguei pickles de', out_dir)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError('Estruturas de parsing n√£o encontradas em mem√≥ria nem em results/q1. Execute a c√©lula de parsing primeiro.')\n",
    "\n",
    "# Calcula grau (n√∫mero de coatores) e seleciona TOP_N\n",
    "degrees = {actor: len(neigh) for actor, neigh in actor_coactors.items()}\n",
    "all_actors_count = len(degrees)\n",
    "sorted_by_degree = sorted(degrees.items(), key=lambda x: x[1], reverse=True)\n",
    "top_actors = sorted_by_degree[:TOP_N]\n",
    "actual_top_n = len(top_actors)\n",
    "print(f\"Atores dispon√≠veis: {all_actors_count}, selecionando TOP_N = {TOP_N} => selecionados: {actual_top_n}\")\n",
    "\n",
    "top_names = [a for a, _ in top_actors]\n",
    "top_set = set(top_names)\n",
    "\n",
    "# Filtrar pares onde ambos est√£o no top\n",
    "filtered_pairs = {pair: cnt for pair, cnt in pair_counts.items() if pair[0] in top_set and pair[1] in top_set}\n",
    "num_filtered_pairs = len(filtered_pairs)\n",
    "print(f\"Pares no subgrafo dos TOP {actual_top_n}: {num_filtered_pairs}\")\n",
    "\n",
    "# --- Usando pandas para gerar os CSVs (mais simples e robusto) ---\n",
    "# links dataframe\n",
    "links_rows = [(a, b, cnt) for (a, b), cnt in filtered_pairs.items()]\n",
    "links_df = pd.DataFrame(links_rows, columns=['Source', 'Target', 'Movies_Count'])\n",
    "links_csv = out_dir / 'links_top.csv'\n",
    "links_df.to_csv(links_csv, index=False)\n",
    "\n",
    "# top actors dataframe\n",
    "top_rows = [(a, degrees.get(a, 0), actor_appearances.get(a, 0)) for a, _ in top_actors]\n",
    "top_df = pd.DataFrame(top_rows, columns=['Actor', 'Degree', 'Appearances'])\n",
    "top_csv = out_dir / 'top_actors.csv'\n",
    "top_df.to_csv(top_csv, index=False)\n",
    "\n",
    "# Salvar pickles √∫teis\n",
    "with open(out_dir / 'filtered_pair_counts.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_pairs, f)\n",
    "with open(out_dir / 'top_actor_names.pkl', 'wb') as f:\n",
    "    pickle.dump(top_names, f)\n",
    "\n",
    "print(f\"Arquivos gerados (n√£o para Flourish ainda):\\n- {links_csv}\\n- {top_csv}\\n- {out_dir / 'filtered_pair_counts.pkl'}\\n- {out_dir / 'top_actor_names.pkl'}\")\n",
    "\n",
    "# Resumo r√°pido dos 10 atores com maior grau selecionados\n",
    "print('\\nTop 10 (dos selecionados) por grau:')\n",
    "for actor, deg in top_actors[:10]:\n",
    "    print(f\"{actor}: grau={deg}, apari√ß√µes={actor_appearances.get(actor, 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca860426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomes no top: 100; pares filtrados: 583\n",
      "Grafo: n√≥s=100, arestas=583\n",
      "Densidade: 0.117778\n",
      "Componentes: 1; maior componente: 100 n√≥s\n",
      "\n",
      "Calculando centralidades... (isso pode levar algum tempo para betweenness se exato)\n",
      "\n",
      "M√©tricas salvas em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/graph_metrics.csv\n",
      "\n",
      "Top 10 por Degree:\n",
      "               Actor  Degree\n",
      "4    Yuichi Nakamura      27\n",
      "2   Takahiro Sakurai      26\n",
      "5          Yuki Kaji      25\n",
      "10      Jun Fukuyama      25\n",
      "25       Daisuke Ono      24\n",
      "75  Nobuhiko Okamoto      23\n",
      "43     Kana Hanazawa      23\n",
      "42         Ai Kayano      23\n",
      "50  Miyuki Sawashiro      22\n",
      "12    Junichi Suwabe      22\n",
      "\n",
      "Top 10 por Betweenness:\n",
      "                 Actor  Betweenness\n",
      "30       Kari Wahlgren     0.417440\n",
      "0          Anupam Kher     0.173614\n",
      "87  Chlo√´ Grace Moretz     0.126796\n",
      "83       Gerard Butler     0.096958\n",
      "89       Paul Giamatti     0.095672\n",
      "27     Elizabeth Banks     0.070178\n",
      "3      Fred Tatasciore     0.062150\n",
      "55       Alfred Molina     0.060203\n",
      "20       Nick Swardson     0.059847\n",
      "4      Yuichi Nakamura     0.051806\n",
      "\n",
      "Top 10 por Closeness:\n",
      "                 Actor  Closeness\n",
      "30       Kari Wahlgren   0.450000\n",
      "87  Chlo√´ Grace Moretz   0.445946\n",
      "89       Paul Giamatti   0.421277\n",
      "3      Fred Tatasciore   0.412500\n",
      "27     Elizabeth Banks   0.409091\n",
      "20       Nick Swardson   0.405738\n",
      "83       Gerard Butler   0.400810\n",
      "66      Rosario Dawson   0.396000\n",
      "1    Samuel L. Jackson   0.392857\n",
      "28     Bobby Cannavale   0.391304\n",
      "\n",
      "Top 10 por PageRank:\n",
      "               Actor  PageRank\n",
      "2   Takahiro Sakurai  0.022188\n",
      "27   Elizabeth Banks  0.021094\n",
      "25       Daisuke Ono  0.020180\n",
      "5          Yuki Kaji  0.019797\n",
      "17      Maya Rudolph  0.018389\n",
      "22      Adam Sandler  0.016935\n",
      "0        Anupam Kher  0.016835\n",
      "35     Molly Shannon  0.015881\n",
      "6     Shah Rukh Khan  0.015163\n",
      "4    Yuichi Nakamura  0.015064\n",
      "\n",
      "Etapa 4 conclu√≠da ‚Äî valide os resultados antes de prosseguirmos para as centralidades mais custosas (se necess√°rio) ou detec√ß√£o de comunidades.\n",
      "               Actor  Degree\n",
      "4    Yuichi Nakamura      27\n",
      "2   Takahiro Sakurai      26\n",
      "5          Yuki Kaji      25\n",
      "10      Jun Fukuyama      25\n",
      "25       Daisuke Ono      24\n",
      "75  Nobuhiko Okamoto      23\n",
      "43     Kana Hanazawa      23\n",
      "42         Ai Kayano      23\n",
      "50  Miyuki Sawashiro      22\n",
      "12    Junichi Suwabe      22\n",
      "\n",
      "Top 10 por Betweenness:\n",
      "                 Actor  Betweenness\n",
      "30       Kari Wahlgren     0.417440\n",
      "0          Anupam Kher     0.173614\n",
      "87  Chlo√´ Grace Moretz     0.126796\n",
      "83       Gerard Butler     0.096958\n",
      "89       Paul Giamatti     0.095672\n",
      "27     Elizabeth Banks     0.070178\n",
      "3      Fred Tatasciore     0.062150\n",
      "55       Alfred Molina     0.060203\n",
      "20       Nick Swardson     0.059847\n",
      "4      Yuichi Nakamura     0.051806\n",
      "\n",
      "Top 10 por Closeness:\n",
      "                 Actor  Closeness\n",
      "30       Kari Wahlgren   0.450000\n",
      "87  Chlo√´ Grace Moretz   0.445946\n",
      "89       Paul Giamatti   0.421277\n",
      "3      Fred Tatasciore   0.412500\n",
      "27     Elizabeth Banks   0.409091\n",
      "20       Nick Swardson   0.405738\n",
      "83       Gerard Butler   0.400810\n",
      "66      Rosario Dawson   0.396000\n",
      "1    Samuel L. Jackson   0.392857\n",
      "28     Bobby Cannavale   0.391304\n",
      "\n",
      "Top 10 por PageRank:\n",
      "               Actor  PageRank\n",
      "2   Takahiro Sakurai  0.022188\n",
      "27   Elizabeth Banks  0.021094\n",
      "25       Daisuke Ono  0.020180\n",
      "5          Yuki Kaji  0.019797\n",
      "17      Maya Rudolph  0.018389\n",
      "22      Adam Sandler  0.016935\n",
      "0        Anupam Kher  0.016835\n",
      "35     Molly Shannon  0.015881\n",
      "6     Shah Rukh Khan  0.015163\n",
      "4    Yuichi Nakamura  0.015064\n",
      "\n",
      "Etapa 4 conclu√≠da ‚Äî valide os resultados antes de prosseguirmos para as centralidades mais custosas (se necess√°rio) ou detec√ß√£o de comunidades.\n"
     ]
    }
   ],
   "source": [
    "# Etapa 4: Construir grafo NetworkX e calcular m√©tricas (densidade, centralidades, PageRank)\n",
    "# Esta c√©lula roda a an√°lise do grafo a partir de `filtered_pair_counts.pkl` e `top_actor_names.pkl`.\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir = root / 'results'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"Nomes no top: {len(top_names)}; pares filtrados: {len(filtered_pairs)}\")\n",
    "\n",
    "# Construir grafo ponderado (undirected)\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(top_names)\n",
    "for (a, b), w in filtered_pairs.items():\n",
    "    # adicionar aresta com atributo weight\n",
    "    G.add_edge(a, b, weight=w)\n",
    "\n",
    "n_nodes = G.number_of_nodes()\n",
    "n_edges = G.number_of_edges()\n",
    "print(f\"Grafo: n√≥s={n_nodes}, arestas={n_edges}\")\n",
    "\n",
    "# M√©tricas globais\n",
    "density = nx.density(G)\n",
    "components = list(nx.connected_components(G))\n",
    "num_components = len(components)\n",
    "largest_cc = max(components, key=len) if components else set()\n",
    "largest_cc_size = len(largest_cc)\n",
    "\n",
    "print(f\"Densidade: {density:.6g}\")\n",
    "print(f\"Componentes: {num_components}; maior componente: {largest_cc_size} n√≥s\")\n",
    "\n",
    "# Centralidades\n",
    "print('\\nCalculando centralidades... (isso pode levar algum tempo para betweenness se exato)')\n",
    "# Degree centrality (normalizada)\n",
    "degree_c = nx.degree_centrality(G)\n",
    "# Betweenness centrality (exata ou aproximada)\n",
    "betweenness_c = nx.betweenness_centrality(G)\n",
    "# Closeness centrality\n",
    "closeness_c = nx.closeness_centrality(G)\n",
    "# PageRank (usa weights)\n",
    "pagerank = nx.pagerank(G, alpha=0.85, max_iter=100)\n",
    "\n",
    "# Degree raw (n√∫mero de vizinhos)\n",
    "degree_raw = dict(G.degree())\n",
    "\n",
    "# Montar DataFrame com m√©tricas\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Actor': list(G.nodes()),\n",
    "    'Degree': [degree_raw.get(n, 0) for n in G.nodes()],\n",
    "    'DegreeCentrality': [degree_c.get(n, 0) for n in G.nodes()],\n",
    "    'Betweenness': [betweenness_c.get(n, 0) for n in G.nodes()],\n",
    "    'Closeness': [closeness_c.get(n, 0) for n in G.nodes()],\n",
    "    'PageRank': [pagerank.get(n, 0) for n in G.nodes()],\n",
    "})\n",
    "\n",
    "# Normalizar colunas (opcional) ‚Äî apenas como colunas separadas para inspe√ß√£o\n",
    "metrics_df['Degree_norm'] = (metrics_df['Degree'] - metrics_df['Degree'].min()) / (metrics_df['Degree'].max() - metrics_df['Degree'].min())\n",
    "metrics_df['Betweenness_norm'] = (metrics_df['Betweenness'] - metrics_df['Betweenness'].min()) / (metrics_df['Betweenness'].max() - metrics_df['Betweenness'].min())\n",
    "metrics_df['Closeness_norm'] = (metrics_df['Closeness'] - metrics_df['Closeness'].min()) / (metrics_df['Closeness'].max() - metrics_df['Closeness'].min())\n",
    "metrics_df['PageRank_norm'] = (metrics_df['PageRank'] - metrics_df['PageRank'].min()) / (metrics_df['PageRank'].max() - metrics_df['PageRank'].min())\n",
    "\n",
    "# Salvar resultados\n",
    "metrics_csv = out_dir / 'graph_metrics.csv'\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "# salvar grafo em gpickle\n",
    "\n",
    "\n",
    "# Mostrar top 10 por cada medida\n",
    "print(f\"\\nM√©tricas salvas em: {metrics_csv}\")\n",
    "\n",
    "print('\\nTop 10 por Degree:')\n",
    "print(metrics_df.sort_values('Degree', ascending=False).head(10)[['Actor','Degree']])\n",
    "print('\\nTop 10 por Betweenness:')\n",
    "print(metrics_df.sort_values('Betweenness', ascending=False).head(10)[['Actor','Betweenness']])\n",
    "print('\\nTop 10 por Closeness:')\n",
    "print(metrics_df.sort_values('Closeness', ascending=False).head(10)[['Actor','Closeness']])\n",
    "print('\\nTop 10 por PageRank:')\n",
    "print(metrics_df.sort_values('PageRank', ascending=False).head(10)[['Actor','PageRank']])\n",
    "\n",
    "# Guardar as vari√°veis no notebook para uso futuro\n",
    "G_graph = G\n",
    "filtered_pairs_graph = filtered_pairs\n",
    "metrics = metrics_df\n",
    "\n",
    "print('\\nEtapa 4 conclu√≠da ‚Äî valide os resultados antes de prosseguirmos para as centralidades mais custosas (se necess√°rio) ou detec√ß√£o de comunidades.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "594e3d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodando Louvain (NetworkX nativo) em n=100 n√≥s, m=583 arestas\n",
      "Par√¢metro de resolu√ß√£o: 1, seed: 42\n",
      "\n",
      "Modularidade obtida: 0.507\n",
      "N√∫mero de comunidades: 3\n",
      "\n",
      "Distribui√ß√£o de tamanhos (min=12, max=61, mean=33.3, median=27.0)\n",
      "\n",
      "================================================================================\n",
      "GERANDO ARQUIVOS PARA FLOURISH\n",
      "================================================================================\n",
      "\n",
      "‚úÖ links.csv gerado:\n",
      "   - 583 arestas\n",
      "   - Arquivo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_coautoria/links.csv\n",
      "\n",
      "‚úÖ points.csv gerado:\n",
      "   - 100 atores\n",
      "   - 3 comunidades\n",
      "   - Arquivo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_coautoria/points.csv\n",
      "\n",
      "================================================================================\n",
      "RESUMO DAS COMUNIDADES\n",
      "================================================================================\n",
      "\n",
      "Top 10 maiores comunidades (ID: tamanho):\n",
      "  1. Comunidade 2: 61 atores\n",
      "  2. Comunidade 1: 27 atores\n",
      "  3. Comunidade 0: 12 atores\n",
      "\n",
      "================================================================================\n",
      "ARQUIVOS FLOURISH PRONTOS!\n",
      "================================================================================\n",
      "\n",
      "üìÅ Diret√≥rio: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/grafo_coautoria\n",
      "   ‚îú‚îÄ‚îÄ links.csv    (583 arestas)\n",
      "   ‚îú‚îÄ‚îÄ points.csv   (100 n√≥s, 3 comunidades)\n",
      "   ‚îú‚îÄ‚îÄ louvain_stats.csv\n",
      "   ‚îî‚îÄ‚îÄ communities_louvain.pkl\n",
      "\n",
      "‚ú® Importe links.csv e points.csv no Flourish Network Graph!\n",
      "   - Use 'id' como node identifier\n",
      "   - Use 'Community' para colorir os n√≥s\n"
     ]
    }
   ],
   "source": [
    "# Etapa 6: Louvain + Gera√ß√£o de arquivos para Flourish\n",
    "# Detecta comunidades com Louvain e gera links.csv e points.csv para visualiza√ß√£o no Flourish\n",
    "\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "from networkx.algorithms.community.quality import modularity\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Par√¢metros ajust√°veis\n",
    "LOUVAIN_RESOLUTION = 1  # padr√£o 1.0; aumentar => mais comunidades\n",
    "USE_LARGEST_CC = True\n",
    "LOUVAIN_SEED = 42  # seed para reprodutibilidade\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir = root / 'results' / 'grafo_coautoria'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Carregar grafo se necess√°rio\n",
    "try:\n",
    "    G\n",
    "    filtered_pairs\n",
    "except NameError:\n",
    "    raise FileNotFoundError('Grafo n√£o encontrado. Execute a c√©lula que constr√≥i o grafo (Etapa 4) primeiro.')\n",
    "\n",
    "# Subgrafo onde rodar Louvain\n",
    "if USE_LARGEST_CC:\n",
    "    comps = list(nx.connected_components(G))\n",
    "    largest = max(comps, key=len)\n",
    "    G_louvain = G.subgraph(largest).copy()\n",
    "else:\n",
    "    G_louvain = G\n",
    "\n",
    "print(f\"Rodando Louvain (NetworkX nativo) em n={G_louvain.number_of_nodes()} n√≥s, m={G_louvain.number_of_edges()} arestas\")\n",
    "print(f\"Par√¢metro de resolu√ß√£o: {LOUVAIN_RESOLUTION}, seed: {LOUVAIN_SEED}\")\n",
    "\n",
    "# Executar Louvain (retorna lista de sets/frozensets)\n",
    "communities_sets = louvain_communities(G_louvain, weight='weight', resolution=LOUVAIN_RESOLUTION, seed=LOUVAIN_SEED)\n",
    "\n",
    "# Converter para lista de listas\n",
    "communities_list = [list(c) for c in communities_sets]\n",
    "\n",
    "# Calcular modularidade\n",
    "mod = modularity(G_louvain, communities_list, weight='weight')\n",
    "num_communities = len(communities_list)\n",
    "\n",
    "print(f\"\\nModularidade obtida: {mod:.3f}\")\n",
    "print(f\"N√∫mero de comunidades: {num_communities}\")\n",
    "\n",
    "# Estat√≠sticas das comunidades\n",
    "sizes = pd.Series([len(c) for c in communities_list])\n",
    "print(f\"\\nDistribui√ß√£o de tamanhos (min={sizes.min()}, max={sizes.max()}, mean={sizes.mean():.1f}, median={sizes.median():.1f})\")\n",
    "\n",
    "# Criar dicion√°rio node -> community_id\n",
    "partition = {}\n",
    "for cid, comm in enumerate(communities_list):\n",
    "    for node in comm:\n",
    "        partition[node] = cid\n",
    "\n",
    "# Estender parti√ß√£o para todos os n√≥s do grafo original\n",
    "comm_dict_louvain = {}\n",
    "for node in G.nodes():\n",
    "    if node in partition:\n",
    "        comm_dict_louvain[node] = partition[node]\n",
    "    else:\n",
    "        comm_dict_louvain[node] = -1  # N√≥s fora do maior componente\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO ARQUIVOS PARA FLOURISH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========== 1. GERAR links.csv ==========\n",
    "# Filtrar apenas arestas do subgrafo Louvain\n",
    "links_data = []\n",
    "for (a, b), weight in filtered_pairs.items():\n",
    "    # Incluir apenas se ambos est√£o no G_louvain\n",
    "    if a in G_louvain.nodes() and b in G_louvain.nodes():\n",
    "        links_data.append((a, b, weight))\n",
    "\n",
    "links_df = pd.DataFrame(links_data, columns=['Source', 'Target', 'Value'])\n",
    "links_csv = out_dir / 'links.csv'\n",
    "links_df.to_csv(links_csv, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ links.csv gerado:\")\n",
    "print(f\"   - {len(links_df)} arestas\")\n",
    "print(f\"   - Arquivo: {links_csv}\")\n",
    "\n",
    "# ========== 2. GERAR points.csv ==========\n",
    "points_data = []\n",
    "for actor in G_louvain.nodes():\n",
    "    points_data.append((\n",
    "        actor,  # id\n",
    "        comm_dict_louvain[actor]  # Community\n",
    "    ))\n",
    "\n",
    "points_df = pd.DataFrame(points_data, columns=['id', 'Community'])\n",
    "points_csv = out_dir / 'points.csv'\n",
    "points_df.to_csv(points_csv, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ points.csv gerado:\")\n",
    "print(f\"   - {len(points_df)} atores\")\n",
    "print(f\"   - {points_df['Community'].nunique()} comunidades\")\n",
    "print(f\"   - Arquivo: {points_csv}\")\n",
    "\n",
    "# ========== 3. SALVAR METADADOS ==========\n",
    "# Salvar stats de Louvain\n",
    "louvain_stats = {\n",
    "    'resolution': LOUVAIN_RESOLUTION,\n",
    "    'seed': LOUVAIN_SEED,\n",
    "    'modularity': mod,\n",
    "    'num_communities': num_communities,\n",
    "    'nodes_analyzed': G_louvain.number_of_nodes(),\n",
    "    'edges_analyzed': G_louvain.number_of_edges()\n",
    "}\n",
    "\n",
    "pd.DataFrame([louvain_stats]).to_csv(out_dir / 'louvain_stats.csv', index=False)\n",
    "\n",
    "# Salvar parti√ß√£o em pickle\n",
    "with open(out_dir / 'communities_louvain.pkl', 'wb') as f:\n",
    "    pickle.dump(comm_dict_louvain, f)\n",
    "\n",
    "# ========== 4. RESUMO DAS COMUNIDADES ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO DAS COMUNIDADES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comm_sizes = points_df['Community'].value_counts().sort_values(ascending=False)\n",
    "print(f\"\\nTop 10 maiores comunidades (ID: tamanho):\")\n",
    "for idx, (comm_id, size) in enumerate(comm_sizes.head(10).items(), 1):\n",
    "    print(f\"  {idx}. Comunidade {comm_id}: {size} atores\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARQUIVOS FLOURISH PRONTOS!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÅ Diret√≥rio: {out_dir}\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ links.csv    ({len(links_df)} arestas)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ points.csv   ({len(points_df)} n√≥s, {num_communities} comunidades)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ louvain_stats.csv\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ communities_louvain.pkl\")\n",
    "print(\"\\n‚ú® Importe links.csv e points.csv no Flourish Network Graph!\")\n",
    "print(\"   - Use 'id' como node identifier\")\n",
    "print(\"   - Use 'Community' para colorir os n√≥s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt108_projeto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
