{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d784b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import time\n",
    "from pathlib import Path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67a834",
   "metadata": {},
   "source": [
    "# Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f61bc40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/datasets/netflix_titles.csv\n"
     ]
    }
   ],
   "source": [
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "# garante que encontramos o dataset independentemente do cwd do notebook\n",
    "input_file = root / 'datasets' / 'netflix_titles.csv'\n",
    "\n",
    "print(f\"Lendo: {input_file}\")\n",
    "\n",
    "df = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab55fb",
   "metadata": {},
   "source": [
    "## Análise geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306758f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas no CSV: 8807\n",
      "Atores com pelo menos 1 co-ator: 36039\n",
      "Atores com aparições registradas: 36439\n",
      "Pares únicos de atores (potenciais arestas): 289207\n",
      "\n",
      "Top 20 por grau (número de coatores):\n",
      "Anupam Kher: 273\n",
      "Samuel L. Jackson: 239\n",
      "Takahiro Sakurai: 228\n",
      "Fred Tatasciore: 226\n",
      "Yuichi Nakamura: 223\n",
      "Yuki Kaji: 220\n",
      "Shah Rukh Khan: 210\n",
      "Fred Armisen: 209\n",
      "Akshay Kumar: 193\n",
      "Katsuyuki Konishi: 191\n",
      "Jun Fukuyama: 188\n",
      "Om Puri: 187\n",
      "Junichi Suwabe: 185\n",
      "Naseeruddin Shah: 183\n",
      "Boman Irani: 183\n",
      "Hiroshi Kamiya: 182\n",
      "James Franco: 182\n",
      "Maya Rudolph: 181\n",
      "Paresh Rawal: 179\n",
      "Amitabh Bachchan: 178\n",
      "\n",
      "Top 20 por aparições:\n",
      "Anupam Kher: 43\n",
      "Shah Rukh Khan: 35\n",
      "Julie Tejwani: 33\n",
      "Naseeruddin Shah: 32\n",
      "Takahiro Sakurai: 32\n",
      "Rupa Bhimani: 31\n",
      "Akshay Kumar: 30\n",
      "Om Puri: 30\n",
      "Yuki Kaji: 29\n",
      "Amitabh Bachchan: 28\n",
      "Paresh Rawal: 28\n",
      "Boman Irani: 27\n",
      "Rajesh Kava: 26\n",
      "Vincent Tong: 26\n",
      "Andrea Libman: 25\n",
      "Kareena Kapoor: 25\n",
      "Samuel L. Jackson: 24\n",
      "John Cleese: 24\n",
      "Jigna Bhardwaj: 23\n",
      "Fred Tatasciore: 23\n",
      "\n",
      "Arquivos intermediários salvos em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2: Parse do CSV e construção das estruturas de co-atores\n",
    "\n",
    "actor_coactors = defaultdict(set)\n",
    "pair_counts = defaultdict(int)\n",
    "actor_appearances = defaultdict(int)\n",
    "\n",
    "for idx, cast in enumerate(df['cast'].fillna('')):\n",
    "    if not cast:\n",
    "        continue\n",
    "    actors = [a.strip() for a in cast.split(',') if a.strip()]\n",
    "    for a in actors:\n",
    "        actor_appearances[a] += 1\n",
    "    for a, b in combinations(actors, 2):\n",
    "        key = tuple(sorted((a, b)))\n",
    "        pair_counts[key] += 1\n",
    "        actor_coactors[a].add(b)\n",
    "        actor_coactors[b].add(a)\n",
    "\n",
    "num_actors_with_coactors = len(actor_coactors)\n",
    "num_actors_with_appearances = len(actor_appearances)\n",
    "num_pairs = len(pair_counts)\n",
    "\n",
    "print(f\"Total de linhas no CSV: {df.shape[0]}\")\n",
    "print(f\"Atores com pelo menos 1 co-ator: {num_actors_with_coactors}\")\n",
    "print(f\"Atores com aparições registradas: {num_actors_with_appearances}\")\n",
    "print(f\"Pares únicos de atores (potenciais arestas): {num_pairs}\")\n",
    "\n",
    "# Tops para inspeção\n",
    "top_by_degree = sorted(((actor, len(neigh)) for actor, neigh in actor_coactors.items()), key=lambda x: x[1], reverse=True)[:20]\n",
    "print('\\nTop 20 por grau (número de coatores):')\n",
    "for actor, deg in top_by_degree:\n",
    "    print(f\"{actor}: {deg}\")\n",
    "\n",
    "top_by_appearances = sorted(actor_appearances.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "print('\\nTop 20 por aparições:')\n",
    "for actor, cnt in top_by_appearances:\n",
    "    print(f\"{actor}: {cnt}\")\n",
    "\n",
    "# Salvando intermediários em results/q1\n",
    "out_dir = root / 'results'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Salvar tops em CSVs para inspeção\n",
    "pd.DataFrame(top_by_appearances, columns=['Actor', 'Appearances']).to_csv(out_dir / 'top_by_appearances.csv', index=False)\n",
    "pd.DataFrame(top_by_degree, columns=['Actor', 'Degree']).to_csv(out_dir / 'top_by_degree.csv', index=False)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nArquivos intermediários salvos em: {out_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07cd31b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atores disponíveis: 36039, selecionando TOP_N = 1000 => selecionados: 1000\n",
      "Pares no subgrafo dos TOP 1000: 15399\n",
      "Arquivos gerados (não para Flourish ainda):\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/links_top.csv\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/top_actors.csv\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/filtered_pair_counts.pkl\n",
      "- /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/q1/top_actor_names.pkl\n",
      "\n",
      "Top 10 (dos selecionados) por grau:\n",
      "Anupam Kher: grau=273, aparições=43\n",
      "Samuel L. Jackson: grau=239, aparições=24\n",
      "Takahiro Sakurai: grau=228, aparições=32\n",
      "Fred Tatasciore: grau=226, aparições=23\n",
      "Yuichi Nakamura: grau=223, aparições=19\n",
      "Yuki Kaji: grau=220, aparições=29\n",
      "Shah Rukh Khan: grau=210, aparições=35\n",
      "Fred Armisen: grau=209, aparições=19\n",
      "Akshay Kumar: grau=193, aparições=30\n",
      "Katsuyuki Konishi: grau=191, aparições=12\n"
     ]
    }
   ],
   "source": [
    "# Etapa 3 (separada): Selecionar TOP_N atores por grau (conexões)\n",
    "# Não executo esta célula automaticamente — confirme quando quiser rodar.\n",
    "\n",
    "# Parâmetro dinâmico: altere antes de executar, se desejar\n",
    "TOP_N = 1000\n",
    "\n",
    "# Determina paths conforme o notebook\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir = root / 'results' / 'q1'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Tenta usar variáveis em memória (caso a célula de parsing tenha sido executada);\n",
    "# caso contrário, carrega os pickles gerados pela etapa de parsing.\n",
    "try:\n",
    "    actor_coactors\n",
    "    pair_counts\n",
    "    actor_appearances\n",
    "except NameError:\n",
    "    # tenta carregar arquivos em results/q1\n",
    "    try:\n",
    "        with open(out_dir / 'actor_coactors.pkl', 'rb') as f:\n",
    "            actor_coactors = pickle.load(f)\n",
    "        with open(out_dir / 'pair_counts.pkl', 'rb') as f:\n",
    "            pair_counts = pickle.load(f)\n",
    "        with open(out_dir / 'actor_appearances.pkl', 'rb') as f:\n",
    "            actor_appearances = pickle.load(f)\n",
    "        print('Carreguei pickles de', out_dir)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError('Estruturas de parsing não encontradas em memória nem em results/q1. Execute a célula de parsing primeiro.')\n",
    "\n",
    "# Calcula grau (número de coatores) e seleciona TOP_N\n",
    "degrees = {actor: len(neigh) for actor, neigh in actor_coactors.items()}\n",
    "all_actors_count = len(degrees)\n",
    "sorted_by_degree = sorted(degrees.items(), key=lambda x: x[1], reverse=True)\n",
    "top_actors = sorted_by_degree[:TOP_N]\n",
    "actual_top_n = len(top_actors)\n",
    "print(f\"Atores disponíveis: {all_actors_count}, selecionando TOP_N = {TOP_N} => selecionados: {actual_top_n}\")\n",
    "\n",
    "top_names = [a for a, _ in top_actors]\n",
    "top_set = set(top_names)\n",
    "\n",
    "# Filtrar pares onde ambos estão no top\n",
    "filtered_pairs = {pair: cnt for pair, cnt in pair_counts.items() if pair[0] in top_set and pair[1] in top_set}\n",
    "num_filtered_pairs = len(filtered_pairs)\n",
    "print(f\"Pares no subgrafo dos TOP {actual_top_n}: {num_filtered_pairs}\")\n",
    "\n",
    "# --- Usando pandas para gerar os CSVs (mais simples e robusto) ---\n",
    "# links dataframe\n",
    "links_rows = [(a, b, cnt) for (a, b), cnt in filtered_pairs.items()]\n",
    "links_df = pd.DataFrame(links_rows, columns=['Source', 'Target', 'Movies_Count'])\n",
    "links_csv = out_dir / 'links_top.csv'\n",
    "links_df.to_csv(links_csv, index=False)\n",
    "\n",
    "# top actors dataframe\n",
    "top_rows = [(a, degrees.get(a, 0), actor_appearances.get(a, 0)) for a, _ in top_actors]\n",
    "top_df = pd.DataFrame(top_rows, columns=['Actor', 'Degree', 'Appearances'])\n",
    "top_csv = out_dir / 'top_actors.csv'\n",
    "top_df.to_csv(top_csv, index=False)\n",
    "\n",
    "# Salvar pickles úteis\n",
    "with open(out_dir / 'filtered_pair_counts.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_pairs, f)\n",
    "with open(out_dir / 'top_actor_names.pkl', 'wb') as f:\n",
    "    pickle.dump(top_names, f)\n",
    "\n",
    "print(f\"Arquivos gerados (não para Flourish ainda):\\n- {links_csv}\\n- {top_csv}\\n- {out_dir / 'filtered_pair_counts.pkl'}\\n- {out_dir / 'top_actor_names.pkl'}\")\n",
    "\n",
    "# Resumo rápido dos 10 atores com maior grau selecionados\n",
    "print('\\nTop 10 (dos selecionados) por grau:')\n",
    "for actor, deg in top_actors[:10]:\n",
    "    print(f\"{actor}: grau={deg}, aparições={actor_appearances.get(actor, 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca860426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomes no top: 1000; pares filtrados: 15399\n",
      "Grafo: nós=1000, arestas=15399\n",
      "Densidade: 0.0308288\n",
      "Componentes: 5; maior componente: 993 nós\n",
      "\n",
      "Calculando centralidades... (isso pode levar algum tempo para betweenness se exato)\n",
      "\n",
      "Métricas salvas em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/graph_metrics.csv\n",
      "\n",
      "Top 10 por Degree:\n",
      "                Actor  Degree\n",
      "2    Takahiro Sakurai     102\n",
      "10       Jun Fukuyama     101\n",
      "4     Yuichi Nakamura      98\n",
      "5           Yuki Kaji      92\n",
      "12     Junichi Suwabe      89\n",
      "9   Katsuyuki Konishi      88\n",
      "25        Daisuke Ono      87\n",
      "43      Kana Hanazawa      80\n",
      "15     Hiroshi Kamiya      80\n",
      "28    Bobby Cannavale      79\n",
      "\n",
      "Top 10 por Betweenness:\n",
      "              Actor  Betweenness\n",
      "0       Anupam Kher     0.094909\n",
      "30    Kari Wahlgren     0.060672\n",
      "11          Om Puri     0.058078\n",
      "430    Danny Glover     0.043636\n",
      "191     Lena Headey     0.038386\n",
      "105  Yuri Lowenthal     0.033009\n",
      "429  Todd Haberkorn     0.031061\n",
      "138    Bimbo Manuel     0.021825\n",
      "64     Ben Kingsley     0.021135\n",
      "55    Alfred Molina     0.020580\n",
      "\n",
      "Top 10 por Closeness:\n",
      "                 Actor  Closeness\n",
      "7         Fred Armisen   0.417394\n",
      "55       Alfred Molina   0.416335\n",
      "89       Paul Giamatti   0.413886\n",
      "191        Lena Headey   0.411810\n",
      "83       Gerard Butler   0.409414\n",
      "39     Terrence Howard   0.407550\n",
      "3      Fred Tatasciore   0.407213\n",
      "1    Samuel L. Jackson   0.406206\n",
      "66      Rosario Dawson   0.405871\n",
      "115       Topher Grace   0.405537\n",
      "\n",
      "Top 10 por PageRank:\n",
      "                Actor  PageRank\n",
      "2    Takahiro Sakurai  0.003351\n",
      "5           Yuki Kaji  0.003069\n",
      "0         Anupam Kher  0.002982\n",
      "25        Daisuke Ono  0.002857\n",
      "6      Shah Rukh Khan  0.002543\n",
      "1   Samuel L. Jackson  0.002508\n",
      "12     Junichi Suwabe  0.002485\n",
      "4     Yuichi Nakamura  0.002482\n",
      "7        Fred Armisen  0.002479\n",
      "35      Molly Shannon  0.002386\n",
      "\n",
      "Etapa 4 concluída — valide os resultados antes de prosseguirmos para as centralidades mais custosas (se necessário) ou detecção de comunidades.\n",
      "\n",
      "Métricas salvas em: /home/afmireski/Documentos/BCC/p8/analise_de_redes_sociais_utilizando_grafos/projeto/opt108_projeto/results/graph_metrics.csv\n",
      "\n",
      "Top 10 por Degree:\n",
      "                Actor  Degree\n",
      "2    Takahiro Sakurai     102\n",
      "10       Jun Fukuyama     101\n",
      "4     Yuichi Nakamura      98\n",
      "5           Yuki Kaji      92\n",
      "12     Junichi Suwabe      89\n",
      "9   Katsuyuki Konishi      88\n",
      "25        Daisuke Ono      87\n",
      "43      Kana Hanazawa      80\n",
      "15     Hiroshi Kamiya      80\n",
      "28    Bobby Cannavale      79\n",
      "\n",
      "Top 10 por Betweenness:\n",
      "              Actor  Betweenness\n",
      "0       Anupam Kher     0.094909\n",
      "30    Kari Wahlgren     0.060672\n",
      "11          Om Puri     0.058078\n",
      "430    Danny Glover     0.043636\n",
      "191     Lena Headey     0.038386\n",
      "105  Yuri Lowenthal     0.033009\n",
      "429  Todd Haberkorn     0.031061\n",
      "138    Bimbo Manuel     0.021825\n",
      "64     Ben Kingsley     0.021135\n",
      "55    Alfred Molina     0.020580\n",
      "\n",
      "Top 10 por Closeness:\n",
      "                 Actor  Closeness\n",
      "7         Fred Armisen   0.417394\n",
      "55       Alfred Molina   0.416335\n",
      "89       Paul Giamatti   0.413886\n",
      "191        Lena Headey   0.411810\n",
      "83       Gerard Butler   0.409414\n",
      "39     Terrence Howard   0.407550\n",
      "3      Fred Tatasciore   0.407213\n",
      "1    Samuel L. Jackson   0.406206\n",
      "66      Rosario Dawson   0.405871\n",
      "115       Topher Grace   0.405537\n",
      "\n",
      "Top 10 por PageRank:\n",
      "                Actor  PageRank\n",
      "2    Takahiro Sakurai  0.003351\n",
      "5           Yuki Kaji  0.003069\n",
      "0         Anupam Kher  0.002982\n",
      "25        Daisuke Ono  0.002857\n",
      "6      Shah Rukh Khan  0.002543\n",
      "1   Samuel L. Jackson  0.002508\n",
      "12     Junichi Suwabe  0.002485\n",
      "4     Yuichi Nakamura  0.002482\n",
      "7        Fred Armisen  0.002479\n",
      "35      Molly Shannon  0.002386\n",
      "\n",
      "Etapa 4 concluída — valide os resultados antes de prosseguirmos para as centralidades mais custosas (se necessário) ou detecção de comunidades.\n"
     ]
    }
   ],
   "source": [
    "# Etapa 4: Construir grafo NetworkX e calcular métricas (densidade, centralidades, PageRank)\n",
    "# Esta célula roda a análise do grafo a partir de `filtered_pair_counts.pkl` e `top_actor_names.pkl`.\n",
    "\n",
    "root = Path().resolve().parent if (Path.cwd().name == 'graphs') else Path().resolve()\n",
    "out_dir = root / 'results'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"Nomes no top: {len(top_names)}; pares filtrados: {len(filtered_pairs)}\")\n",
    "\n",
    "# Construir grafo ponderado (undirected)\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(top_names)\n",
    "for (a, b), w in filtered_pairs.items():\n",
    "    # adicionar aresta com atributo weight\n",
    "    G.add_edge(a, b, weight=w)\n",
    "\n",
    "n_nodes = G.number_of_nodes()\n",
    "n_edges = G.number_of_edges()\n",
    "print(f\"Grafo: nós={n_nodes}, arestas={n_edges}\")\n",
    "\n",
    "# Métricas globais\n",
    "density = nx.density(G)\n",
    "components = list(nx.connected_components(G))\n",
    "num_components = len(components)\n",
    "largest_cc = max(components, key=len) if components else set()\n",
    "largest_cc_size = len(largest_cc)\n",
    "\n",
    "print(f\"Densidade: {density:.6g}\")\n",
    "print(f\"Componentes: {num_components}; maior componente: {largest_cc_size} nós\")\n",
    "\n",
    "# Centralidades\n",
    "print('\\nCalculando centralidades... (isso pode levar algum tempo para betweenness se exato)')\n",
    "# Degree centrality (normalizada)\n",
    "degree_c = nx.degree_centrality(G)\n",
    "# Betweenness centrality (exata ou aproximada)\n",
    "betweenness_c = nx.betweenness_centrality(G)\n",
    "# Closeness centrality\n",
    "closeness_c = nx.closeness_centrality(G)\n",
    "# PageRank (usa weights)\n",
    "pagerank = nx.pagerank(G, alpha=0.85, max_iter=100)\n",
    "\n",
    "# Degree raw (número de vizinhos)\n",
    "degree_raw = dict(G.degree())\n",
    "\n",
    "# Montar DataFrame com métricas\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Actor': list(G.nodes()),\n",
    "    'Degree': [degree_raw.get(n, 0) for n in G.nodes()],\n",
    "    'DegreeCentrality': [degree_c.get(n, 0) for n in G.nodes()],\n",
    "    'Betweenness': [betweenness_c.get(n, 0) for n in G.nodes()],\n",
    "    'Closeness': [closeness_c.get(n, 0) for n in G.nodes()],\n",
    "    'PageRank': [pagerank.get(n, 0) for n in G.nodes()],\n",
    "})\n",
    "\n",
    "# Normalizar colunas (opcional) — apenas como colunas separadas para inspeção\n",
    "metrics_df['Degree_norm'] = (metrics_df['Degree'] - metrics_df['Degree'].min()) / (metrics_df['Degree'].max() - metrics_df['Degree'].min())\n",
    "metrics_df['Betweenness_norm'] = (metrics_df['Betweenness'] - metrics_df['Betweenness'].min()) / (metrics_df['Betweenness'].max() - metrics_df['Betweenness'].min())\n",
    "metrics_df['Closeness_norm'] = (metrics_df['Closeness'] - metrics_df['Closeness'].min()) / (metrics_df['Closeness'].max() - metrics_df['Closeness'].min())\n",
    "metrics_df['PageRank_norm'] = (metrics_df['PageRank'] - metrics_df['PageRank'].min()) / (metrics_df['PageRank'].max() - metrics_df['PageRank'].min())\n",
    "\n",
    "# Salvar resultados\n",
    "metrics_csv = out_dir / 'graph_metrics.csv'\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "# salvar grafo em gpickle\n",
    "\n",
    "\n",
    "# Mostrar top 10 por cada medida\n",
    "print(f\"\\nMétricas salvas em: {metrics_csv}\")\n",
    "\n",
    "print('\\nTop 10 por Degree:')\n",
    "print(metrics_df.sort_values('Degree', ascending=False).head(10)[['Actor','Degree']])\n",
    "print('\\nTop 10 por Betweenness:')\n",
    "print(metrics_df.sort_values('Betweenness', ascending=False).head(10)[['Actor','Betweenness']])\n",
    "print('\\nTop 10 por Closeness:')\n",
    "print(metrics_df.sort_values('Closeness', ascending=False).head(10)[['Actor','Closeness']])\n",
    "print('\\nTop 10 por PageRank:')\n",
    "print(metrics_df.sort_values('PageRank', ascending=False).head(10)[['Actor','PageRank']])\n",
    "\n",
    "# Guardar as variáveis no notebook para uso futuro\n",
    "G_graph = G\n",
    "filtered_pairs_graph = filtered_pairs\n",
    "metrics = metrics_df\n",
    "\n",
    "print('\\nEtapa 4 concluída — valide os resultados antes de prosseguirmos para as centralidades mais custosas (se necessário) ou detecção de comunidades.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt108_projeto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
